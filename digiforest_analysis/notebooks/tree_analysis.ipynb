{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets # for interactive sliders\n",
    "import pickle\n",
    "from timeit import timeit\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "from digiforest_analysis.utils.timing import Timer\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"/home/ori/git/realtime-trees/single_trees/clustering_2/\"\n",
    "SLICE_HEIGHT = 0.5\n",
    "TREE_ID = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = DATASET_DIR + \"tree\" + str(TREE_ID).zfill(3) + \".pkl\"\n",
    "with open(file_name, 'rb') as file:\n",
    "    cluster = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_height = 2.0\n",
    "slice_thickness = 2.0\n",
    "cloud = cluster['cloud'].point.positions.numpy()\n",
    "slice = cloud[np.logical_and(cloud[:, 2] >= slice_height - slice_thickness / 2, cloud[:, 2] < slice_height + slice_thickness / 2,)][:, :2]\n",
    "print(len(slice))\n",
    "\n",
    "# timing_hough = timeit(\"Circle.from_cloud_hough(slice)\", \"from __main__ import Circle, slice\", number=1000)\n",
    "# print(f\"Hough algo took {timing_hough:.3f} ms\")\n",
    "# timing_new = timeit(\"new_hough(slice)\", \"from __main__ import new_hough, slice\", number=1000)\n",
    "# print(f\"New algo took {timing_new:.3f} ms\")\n",
    "\n",
    "with timer(\"OLD\"):\n",
    "    circ_hough = Circle.from_cloud_hough(slice)\n",
    "with timer(\"NEW\"):\n",
    "    # circ_new, circles = Circle.from_cloud_ransahc(slice, min_radius=0.05, max_radius=0.5, sampling=\"weighted\", max_points=100)\n",
    "    circ_new = Circle.from_cloud_ransahc(slice, min_radius=0.05, max_radius=0.5, sampling=\"weighted\", max_circles=500)\n",
    "\n",
    "print(timer)\n",
    "plt.scatter(slice[:, 0], slice[:, 1], s=5)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "# plot circle\n",
    "plt.gca().add_artist(plt.Circle((circ_hough.x, circ_hough.y), circ_hough.radius, color='r', fill=False))\n",
    "plt.gca().add_artist(plt.Circle((circ_new.x, circ_new.y), circ_new.radius, color='g', fill=False))\n",
    "# plt.scatter(circles[:, 0], circles[:, 1], s=5, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import pickle, os\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "# %matplotlib notebook\n",
    "\n",
    "path = \"/home/ori/git/digiforest_drs/trees/logs/raw\"\n",
    "TREE_ID = 12\n",
    "tree_path = os.path.join(path, f\"tree{TREE_ID:03d}.pkl\")\n",
    "with open(tree_path, 'rb') as file:\n",
    "    tree : Tree = pickle.load(file)\n",
    "\n",
    "def align_clouds(clusters):\n",
    "    trafos_map = [c[\"info\"][\"T_sensor2map\"] @ c[\"info\"][\"axis\"][\"transform\"] for c in clusters]\n",
    "    clouds_map = [c[\"cloud\"].point.positions.numpy() @ c[\"info\"][\"T_sensor2map\"][:3, :3].T + c[\"info\"][\"T_sensor2map\"][:3, 3] for c in clusters]\n",
    "    mean_position = np.mean([t[:3, 3] for t in trafos_map], axis=0)\n",
    "    deltas = [t[:3, 3] - mean_position for t in trafos_map]\n",
    "    deltas = [np.array([d[0], d[1], 0]) for d in deltas]\n",
    "    return [c - d for c, d in zip(clouds_map, deltas)]\n",
    "\n",
    "\n",
    "# make a 2d plot with a slider that changes the height of the slice\n",
    "clouds = [\n",
    "    cluster['cloud'].point.positions.numpy() @ cluster['info']['T_sensor2map'][:3, :3].T + cluster['info']['T_sensor2map'][:3, 3]\n",
    "    for cluster in tree.clusters\n",
    "]\n",
    "clouds_aligned = align_clouds(tree.clusters)\n",
    "cloud_merged = np.concatenate(clouds, axis=0)\n",
    "cloud_aligned_merged = np.concatenate(clouds_aligned, axis=0)\n",
    "# cloud_aligned_merged = tree.points\n",
    "hues = np.linspace(0, 1, len(clouds) + 1)[:len(clouds)]\n",
    "colors = [colorsys.hsv_to_rgb(h, 1, 1) for h in hues]\n",
    "\n",
    "slice_thickness = 0.2\n",
    "# min and max width and height are 10th and 90 th percentiles\n",
    "min_width, max_width = np.percentile(cloud_merged[:, 0], [2, 98])\n",
    "min_height, max_height = np.percentile(cloud_merged[:, 1], [2, 98])\n",
    "@widgets.interact(height=widgets.FloatSlider(min=cloud_merged[:, 2].min(), max=cloud_merged[:, 2].max(), step=0.3, value=0.0))\n",
    "def update_slice_height(height):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    for a in ax:\n",
    "        a.set_aspect('equal', adjustable='box')\n",
    "        a.set_xlim(min_width, max_width)\n",
    "        a.set_ylim(min_height, max_height)\n",
    "    for cloud, color in zip(clouds, colors):\n",
    "        slice = cloud[np.logical_and(cloud[:, 2] >= height - slice_thickness / 2, cloud[:, 2] < height + slice_thickness / 2,)][:, :2]\n",
    "        ax[0].scatter(slice[:, 0], slice[:, 1], s=1, color=color)\n",
    "    for cloud, color in zip(clouds_aligned, colors):\n",
    "        slice = cloud[np.logical_and(cloud[:, 2] >= height - slice_thickness / 2, cloud[:, 2] < height + slice_thickness / 2,)][:, :2]\n",
    "        ax[1].scatter(slice[:, 0], slice[:, 1], s=1, color=color)\n",
    "    slice_merged = cloud_merged[np.logical_and(cloud_merged[:, 2] >= height - slice_thickness / 2, cloud_merged[:, 2] < height + slice_thickness / 2,)][:, :2]\n",
    "    slice_aligned_merged = cloud_aligned_merged[np.logical_and(cloud_aligned_merged[:, 2] >= height - slice_thickness / 2, cloud_aligned_merged[:, 2] < height + slice_thickness / 2,)][:, :2]\n",
    "    ax[2].scatter(slice_aligned_merged[:, 0], slice_aligned_merged[:, 1], s=1, color='k')\n",
    "    # fit hough circle\n",
    "    center_region = Circle(tree.axis[\"transform\"][:3, 3], tree.axis[\"radius\"])\n",
    "    min_radius = 0.5 * tree.axis[\"radius\"]\n",
    "    max_radius = 1.5 * tree.axis[\"radius\"]\n",
    "    circ_hough = Circle.from_cloud_hough(slice_merged, min_radius=0.05, max_radius=0.5)\n",
    "    circ_hough_aligned = Circle.from_cloud_hough(slice_aligned_merged, min_radius=0.05, max_radius=0.5)\n",
    "    circ_ransahc = Circle.from_cloud_ransahc(slice_merged, min_radius=min_radius, max_radius=max_radius, center_region=center_region)\n",
    "    circ_ransahc_aligned = Circle.from_cloud_ransahc(slice_aligned_merged, min_radius=min_radius, max_radius=max_radius, center_region=center_region)\n",
    "    ax[0].add_artist(plt.Circle((circ_hough.x, circ_hough.y), circ_hough.radius, color='r', fill=False, linewidth=2))\n",
    "    ax[0].add_artist(plt.Circle((circ_ransahc.x, circ_ransahc.y), circ_ransahc.radius, color='g', fill=False, linewidth=2))\n",
    "    ax[2].add_artist(plt.Circle((circ_hough_aligned.x, circ_hough_aligned.y), circ_hough_aligned.radius, color='r', fill=False, linewidth=2))\n",
    "    ax[2].add_artist(plt.Circle((circ_ransahc_aligned.x, circ_ransahc_aligned.y), circ_ransahc_aligned.radius, color='g', fill=False, linewidth=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import colorsys\n",
    "import pickle, os\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "\n",
    "path = \"/home/ori/git/digiforest_drs/trees/logs/raw\"\n",
    "TREE_ID = 50\n",
    "tree_path = os.path.join(path, f\"tree{TREE_ID:03d}.pkl\")\n",
    "with open(tree_path, 'rb') as file:\n",
    "    tree : Tree = pickle.load(file) \n",
    "\n",
    "# clouds = [cluster['cloud'].transform(cluster['info']['T_sensor2map']).point.positions.numpy() for cluster in tree.clusters]\n",
    "clouds = [cluster['cloud'].point.positions.numpy() @ cluster['info']['T_sensor2map'][:3, :3].T + cluster['info']['T_sensor2map'][:3, 3]for cluster in tree.clusters]\n",
    "hues = np.linspace(0, 1, len(clouds) + 1) [:len(clouds)]\n",
    "colors = np.concatenate([np.array([[colorsys.hls_to_rgb(h, 0.6, 1)]]*len(c)) for h, c in zip(hues, clouds)]).squeeze()\n",
    "# for cluster in tree.clusters:\n",
    "#     axis_trafo = cluster[\"info\"]['T_sensor2map'] @ cluster[\"info\"][\"axis\"][\"transform\"]\n",
    "#     circle_lower = Circle(axis_trafo[:3, 3], cluster[\"info\"][\"axis\"][\"radius\"], axis_trafo[:3, 2])\n",
    "#     circle_lower = Circle(axis_trafo[:3, 3] + axis_trafo[:3, 2] * cluster)\n",
    "#     verts, tris = circle_lower.generate_cone_frustum_mesh(circle_upper)\n",
    "#     verts_vec = o3d.utility.Vector3dVector(verts)\n",
    "#     tris_vec = o3d.utility.Vector3iVector(\n",
    "#         np.concatenate((tris, np.flip(tris, axis=1)), axis=0)\n",
    "#     )\n",
    "#     terrain_mesh = o3d.geometry.TriangleMesh(verts_vec, tris_vec)\n",
    "# raise ValueError\n",
    "cloud_aligned = tree.points\n",
    "o3d_cloud = o3d.t.geometry.PointCloud(np.vstack(clouds))\n",
    "o3d_cloud_aligned = o3d.t.geometry.PointCloud(cloud_aligned)\n",
    "o3d_cloud.point.colors = colors\n",
    "o3d_cloud_aligned.point.colors = colors\n",
    "\n",
    "# min_height = 5\n",
    "# max_height = 6\n",
    "# mask = np.logical_and(o3d_cloud.point.positions.numpy()[:, 2] > min_height, o3d_cloud.point.positions.numpy()[:, 2] < max_height)\n",
    "# o3d_cloud = o3d_cloud.select_by_mask(mask)\n",
    "# mask = np.logical_and(o3d_cloud_aligned.point.positions.numpy()[:, 2] > min_height, o3d_cloud_aligned.point.positions.numpy()[:, 2] < max_height)\n",
    "# o3d_cloud_aligned = o3d_cloud_aligned.select_by_mask(mask)\n",
    "\n",
    "aligned_cloud_flag = False\n",
    "\n",
    "def toggle_point_cloud(vis):\n",
    "    global aligned_cloud_flag\n",
    "    current_view = vis.get_view_control().convert_to_pinhole_camera_parameters()\n",
    "    \n",
    "    if aligned_cloud_flag:\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(o3d_cloud_aligned.to_legacy())\n",
    "        aligned_cloud_flag = False\n",
    "        print(\"Showing Aligned Cloud\")\n",
    "    else:\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(o3d_cloud.to_legacy())\n",
    "        print(\"Showing Non-Aligned Cloud\")\n",
    "        aligned_cloud_flag = True\n",
    "    vis.get_view_control().convert_from_pinhole_camera_parameters(current_view, True)\n",
    "\n",
    "visualizer = o3d.visualization.VisualizerWithKeyCallback()\n",
    "visualizer.create_window()\n",
    "visualizer.add_geometry(o3d_cloud.to_legacy())\n",
    "visualizer.register_key_callback(ord(\"C\"), toggle_point_cloud)\n",
    "visualizer.run()\n",
    "visualizer.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os, time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "\n",
    "path = \"/home/ori/git/digiforest_drs/trees/logs/raw\"\n",
    "TREE_ID = 63\n",
    "tree_path = os.path.join(path, f\"tree{TREE_ID:03d}.pkl\")\n",
    "with open(tree_path, 'rb') as file:\n",
    "    tree : Tree = pickle.load(file) \n",
    "TIME = time.perf_counter()\n",
    "print(tree.reconstruct2(max_radius_deviation=100))\n",
    "print(time.perf_counter() - TIME)   \n",
    "\n",
    "# # DEBUG inside tree.reconstruct2\n",
    "# from matplotlib import pyplot as plt\n",
    "# import matplotlib\n",
    "# import numpy as np\n",
    "# import colorsys\n",
    "# matplotlib.use(\"TKagg\")\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.set_xlabel(\"x\")\n",
    "# ax.set_ylabel(\"y\")\n",
    "# ax.set_xlim((-0.5, 0.5))\n",
    "# ax.set_ylim((-0.5, 0.4))\n",
    "# ax.set_title(\"Averaging of individual Payload Clouds\")\n",
    "# ax.set_aspect('equal', adjustable='box')\n",
    "# hues = np.linspace(0, 1, len(ransahc_circles) + 1)[:len(ransahc_circles)]\n",
    "# colors = [list(colorsys.hls_to_rgb(hue, 0.55, 0.8)) for hue in hues]\n",
    "# for points, circle, color in zip(debug_slice_points, ransahc_circles, colors):\n",
    "#     ax.scatter(points[:, 0], points[:, 1], c=[color]*len(points), s=2)\n",
    "#     ax.add_artist(plt.Circle((circle.x, circle.y), circle.radius, color=color, fill=False))\n",
    "# ax.add_artist(plt.Circle((circle.x, circle.y), circle.radius, color=\"g\", linestyle='dashed', fill=False, linewidth=5))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digiforest_analysis_ros.src.digiforest_analysis_ros.forest_analysis import TreeManager\n",
    "import pickle, os\n",
    "\n",
    "path = \"/home/ori/git/digiforest_drs/trees/logs/raw_sar_exp03\"\n",
    "tm = TreeManager()\n",
    "trees = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".pkl\"):\n",
    "        with open(os.path.join(path, file), 'rb') as f:\n",
    "            tree = pickle.load(f)\n",
    "            trees.append(tree)\n",
    "tm.trees = trees\n",
    "tm.num_trees = len(trees)\n",
    "# write back pickle of tm\n",
    "with open(os.path.join(path, \"tree_manager.pkl\"), 'wb') as f:\n",
    "    pickle.dump(tm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import csv, os, pickle\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Error)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "from digiforest_analysis_ros.forest_analysis import TreeManager\n",
    "from digiforest_analysis.tasks.terrain_fitting import TerrainFitting\n",
    "from digiforest_analysis.utils.distances import distance_line_to_line\n",
    "\n",
    "def load_tuples(data_path, tree_manager):\n",
    "    april_tag_pos_path = os.path.join(data_path, \"april_tag_locations.csv\")\n",
    "    april_tag_measurement_path = os.path.join(data_path, \"forester_data.csv\")\n",
    "    ground_cloud_path = os.path.join(data_path, \"ground_cloud.las\")\n",
    "\n",
    "    # reconstructed trees\n",
    "    ours_trees = tree_manager.trees\n",
    "\n",
    "    # ground truth trees\n",
    "    id = 0\n",
    "    tls_trees = []\n",
    "    for file_name in os.listdir(data_path):\n",
    "        if file_name.endswith(\".csv\") and \"_result\" in file_name:\n",
    "            with open(os.path.join(data_path, file_name), 'r') as file:\n",
    "                csv_reader = csv.DictReader(file)\n",
    "                circle_stack = []\n",
    "                for row in csv_reader:\n",
    "                    circle = Circle(\n",
    "                        np.array([\n",
    "                            float(row[\"center_x\"]),\n",
    "                            float(row[\"center_y\"]),\n",
    "                            float(row[\"slice_height\"])\n",
    "                        ]), \n",
    "                        float(row[\"radius\"]))\n",
    "                    circle_stack.append(circle)\n",
    "                \n",
    "                tree = Tree(id)\n",
    "                tree.reconstructed = True\n",
    "                tree.circles = circle_stack\n",
    "                transform = np.eye(4)\n",
    "                dir_vec = circle_stack[2].center - circle_stack[1].center\n",
    "                dir_vec /= np.linalg.norm(dir_vec)\n",
    "                dir_vec_normal = np.array([-dir_vec[1], dir_vec[0], 0])\n",
    "                dir_vec_normal /= np.linalg.norm(dir_vec_normal)\n",
    "                transform[:3, 2] = dir_vec\n",
    "                transform[:3, 0] = dir_vec_normal\n",
    "                transform[:3, 1] = np.cross(dir_vec, dir_vec_normal)\n",
    "                transform[:3, 3] = circle_stack[0].center\n",
    "                tree.clusters = [{\n",
    "                    \"info\": {\n",
    "                        \"T_sensor2map\": np.eye(4),\n",
    "                        \"axis\": {\n",
    "                            \"transform\": transform,\n",
    "                            \"radius\": circle_stack[0].radius\n",
    "                        },\n",
    "                        \"file\": file_name\n",
    "                    }\n",
    "                }]\n",
    "                tls_trees.append(tree)\n",
    "                id += 1\n",
    "\n",
    "    # april tags\n",
    "    with open(april_tag_pos_path, 'r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        april_tag_positions = {int(row[\"tag_id\"]): np.array([float(row[\"x\"]), float(row[\"y\"]), float(row[\"z\"])]) for row in csv_reader}\n",
    "\n",
    "    # manual DBHs\n",
    "    dbhs = {}\n",
    "    with open(april_tag_measurement_path, 'r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            if row[\"DBH [cm]\"] == \"\":\n",
    "                continue\n",
    "            dbhs[int(row[\"Tree\"])] = float(row[\"DBH [cm]\"].replace(\",\", \".\"))\n",
    "\n",
    "    # tree matching\n",
    "    tree_tuples = []\n",
    "    for i_gt, tls_tree in enumerate(tls_trees):\n",
    "        result = {\"tls_tree\": tls_tree,}\n",
    "        gt_axis = {\"transform\": tls_tree.axis[\"transform\"]}\n",
    "        matches = 0\n",
    "        for ours_tree in ours_trees:\n",
    "            ours_axis = {\"transform\": ours_tree.axis[\"transform\"]}\n",
    "            dist = distance_line_to_line(gt_axis, ours_axis, clip_heights=[0,10])\n",
    "            if dist < 0.5:\n",
    "                result[\"ours_tree\"] = ours_tree\n",
    "        for k, v in april_tag_positions.items():\n",
    "            if np.linalg.norm(v[:2] - tls_tree.axis[\"transform\"][:2, 3]) < 0.5:\n",
    "                result[\"april_tag\"] = k \n",
    "                result[\"manual_dbh\"] = dbhs[k]\n",
    "        if \"ours_tree\" in result:\n",
    "            tree_tuples.append(result)\n",
    "\n",
    "    print(f\"Detection Precision: {len(tree_tuples) / id * 100 :.2f} %\")\n",
    "\n",
    "    terrain_cloud = laspy.read(ground_cloud_path)\n",
    "    terrain_cloud = np.vstack((terrain_cloud.x, terrain_cloud.y, terrain_cloud.z)).T\n",
    "    terrain_cloud = o3d.t.geometry.PointCloud(terrain_cloud)\n",
    "    terrain = TerrainFitting().process(cloud=terrain_cloud)\n",
    "    terrain_interpolator = RegularGridInterpolator(\n",
    "        points=(terrain[:, 0, 0], terrain[0, :, 1]),\n",
    "        values=terrain[:, :, 2],\n",
    "        method=\"linear\",\n",
    "        bounds_error=False,\n",
    "        fill_value=None\n",
    "    )\n",
    "    return tree_tuples, terrain, terrain_interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "datasets = {\"mixed\": {}, \"deciduous\": {}, \"conifer\": {}}\n",
    "paths = {\n",
    "    \"mixed\": \"/home/ori/datasets/digiforest_gt_prefor_M\",\n",
    "    \"deciduous\": \"/home/ori/datasets/digiforest_gt_prefor_D\",\n",
    "    \"conifer\": \"/home/ori/datasets/digiforest_gt_prefor_C\"\n",
    "}\n",
    "OURS_COLOR = \"#0173b2\"\n",
    "TLS_COLOR = \"#de8f05\"\n",
    "MANUAL_COLOR = \"#029e73\"\n",
    "\n",
    "MIXED_MARKER = \"o\"\n",
    "DECIDUOUS_MARKER = \"x\"\n",
    "CONIFER_MARKER = \"^\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_type in datasets.keys():\n",
    "    print(f\"Loading {plot_type} dataset\")\n",
    "    with open(os.path.join(paths[plot_type], \"tree_manager.pkl\"), 'rb') as file:\n",
    "        tm : TreeManager = pickle.load(file)\n",
    "    tree_tuples, terrain, terrain_interpolator = load_tuples(paths[plot_type], tm)\n",
    "    datasets[plot_type][\"tuples\"] = tree_tuples\n",
    "    datasets[plot_type][\"terrain\"] = {\"mesh_grid\": terrain, \"interpolator\": terrain_interpolator}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 01: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from digiforest_analysis.utils.meshing import meshgrid_to_mesh\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "\n",
    "selection = None\n",
    "# plot_types = [\"mixed\", \"deciduous\", \"conifer\"]\n",
    "plot_types = [\"conifer\"]\n",
    "max_radii = {\"mixed\": 0.25, \"deciduous\": 0.15, \"conifer\": 0.5}\n",
    "out_dir = \"/home/ori/git/digiforest_drs/trees/evaluation/weighting_test\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "suffix = \"\"\n",
    "num_runs = 1\n",
    "\n",
    "for plot_type in plot_types:\n",
    "    for i_run in range(num_runs):\n",
    "        tree_tuples = datasets[plot_type][\"tuples\"]\n",
    "        terrain = datasets[plot_type][\"terrain\"][\"mesh_grid\"]\n",
    "        terrain_interpolator = datasets[plot_type][\"terrain\"][\"interpolator\"]\n",
    "        \n",
    "        data_path = paths[plot_type]\n",
    "        if selection:\n",
    "            tree_pair_iter = tqdm(tree_tuples[selection: selection+1])\n",
    "        else:\n",
    "            tree_pair_iter = tqdm(tree_tuples)\n",
    "\n",
    "        manual_dbhs = []\n",
    "        tls_dbhs = []\n",
    "        ours_dbhs = []\n",
    "        viz_objects = []\n",
    "        for tree_pair in tree_pair_iter:\n",
    "            ground_elevation = terrain_interpolator(tree_pair[\"tls_tree\"].axis[\"transform\"][:2, 3])[0]\n",
    "            # manual measurement\n",
    "            manual_dbhs.append(tree_pair[\"manual_dbh\"] if \"manual_dbh\" in tree_pair else np.nan)\n",
    "            \n",
    "            # TLS measurement\n",
    "            tls_tree : Tree = tree_pair[\"tls_tree\"]\n",
    "            tls_tree.compute_dbh(ground_elevation)\n",
    "            tls_dbhs.append(tls_tree.dbh * 100 if tls_tree.dbh is not None else np.nan)\n",
    "            \n",
    "            # Ours measurement\n",
    "            ours_tree : Tree = tree_pair[\"ours_tree\"]\n",
    "            time_before = perf_counter()\n",
    "            if ours_tree.reconstruct3(max_radius=max_radii[plot_type]):\n",
    "                reco_time = perf_counter() - time_before\n",
    "                ours_tree.__dict__[\"reco_time\"] = reco_time\n",
    "                ours_tree.compute_dbh(ground_elevation)\n",
    "                ours_dbhs.append(ours_tree.dbh * 100 if ours_tree.dbh is not None else np.nan)\n",
    "            else:\n",
    "                ours_tree.__dict__[\"reco_time\"] = np.nan\n",
    "                ours_dbhs.append(np.nan)\n",
    "            \n",
    "            if tls_tree.dbh is not None and ours_tree.dbh is not None:\n",
    "                verts, tris = tls_tree.generate_mesh()\n",
    "                mesh = o3d.geometry.TriangleMesh(o3d.utility.Vector3dVector(verts), o3d.utility.Vector3iVector(tris))\n",
    "                mesh.paint_uniform_color([0.2, 0.8, 0.2])\n",
    "                mesh.compute_vertex_normals()\n",
    "                viz_objects.append(mesh)\n",
    "                \n",
    "                verts, tris = ours_tree.generate_mesh()\n",
    "                mesh = o3d.geometry.TriangleMesh(o3d.utility.Vector3dVector(verts), o3d.utility.Vector3iVector(tris))\n",
    "                mesh.paint_uniform_color([0.8, 0.2, 0.2])\n",
    "                mesh.compute_vertex_normals()\n",
    "                viz_objects.append(mesh)\n",
    "                \n",
    "                point_cloud = o3d.t.geometry.PointCloud(ours_tree.points)\n",
    "                point_cloud.paint_uniform_color([0, 0, 1])\n",
    "                point_cloud = point_cloud.to_legacy()\n",
    "                viz_objects.append(point_cloud)\n",
    "\n",
    "        verts, tris = meshgrid_to_mesh(terrain)\n",
    "        mesh = o3d.geometry.TriangleMesh(\n",
    "            o3d.utility.Vector3dVector(verts),\n",
    "            o3d.utility.Vector3iVector(tris)\n",
    "        )\n",
    "        mesh.compute_vertex_normals()\n",
    "        viz_objects.append(mesh)\n",
    "\n",
    "        if not selection:\n",
    "            data = []\n",
    "            for i in range(len(tree_tuples)):\n",
    "                tree_tuple = tree_tuples[i]\n",
    "                data_dict = {\n",
    "                    \"file_name\": tree_tuple[\"tls_tree\"].clusters[0][\"info\"][\"file\"],\n",
    "                    \"reco_time\": tree_tuple[\"ours_tree\"].reco_time,\n",
    "                    \"ours_id\": tree_tuple[\"ours_tree\"].id,\n",
    "                    \"manual_dbh\": manual_dbhs[i],\n",
    "                    \"tls_dbh\": tls_dbhs[i],\n",
    "                    \"ours_dbh\": ours_dbhs[i]\n",
    "                }\n",
    "                if tree_tuple[\"ours_tree\"].reconstructed:\n",
    "                    data_dict.update({\n",
    "                        \"ours_centers_x\": [c.center[0] for c in tree_tuple[\"ours_tree\"].circles],\n",
    "                        \"ours_centers_y\": [c.center[1] for c in tree_tuple[\"ours_tree\"].circles],\n",
    "                        \"ours_centers_z\": [c.center[2] for c in tree_tuple[\"ours_tree\"].circles],\n",
    "                        \"ours_radii\": [c.radius for c in tree_tuple[\"ours_tree\"].circles],\n",
    "                    })\n",
    "                else: \n",
    "                    data_dict.update({\"ours_centers_x\": [], \"ours_centers_y\": [], \"ours_centers_z\": [], \"ours_radii\": []})\n",
    "                if tree_tuple[\"tls_tree\"].reconstructed:\n",
    "                    data_dict.update({\n",
    "                        \"tls_centers_x\": [c.center[0] for c in tree_tuple[\"tls_tree\"].circles],\n",
    "                        \"tls_centers_y\": [c.center[1] for c in tree_tuple[\"tls_tree\"].circles],\n",
    "                        \"tls_centers_z\": [c.center[2] for c in tree_tuple[\"tls_tree\"].circles], \n",
    "                        \"tls_radii\": [c.radius for c in tree_tuple[\"tls_tree\"].circles],\n",
    "                    })\n",
    "                else:\n",
    "                    data_dict.update({\"tls_centers_x\": [], \"tls_centers_y\": [], \"tls_centers_z\": [], \"tls_radii\": []})\n",
    "                data.append(data_dict)\n",
    "            suffixes = {\"M\": \"mixed\", \"D\": \"deciduous\", \"C\": \"conifer\"}\n",
    "            if out_dir is not None:\n",
    "                with open(\n",
    "                    os.path.join(out_dir, \n",
    "                                f\"{suffixes[data_path[-1]]}_{suffix}_{i_run}.csv\"), \"w+\") as file:\n",
    "                    csv_writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "                    csv_writer.writeheader()\n",
    "                    csv_writer.writerows(data)\n",
    "\n",
    "            measurements = np.stack([tls_dbhs, manual_dbhs, ours_dbhs], axis=1)\n",
    "            mask = ~np.isnan(measurements).any(axis=1)\n",
    "            msrmnt_triplets = measurements[mask]\n",
    "            sorting = np.argsort(msrmnt_triplets[:, 1])[::-1]\n",
    "            msrmnt_triplets = msrmnt_triplets[sorting]\n",
    "            sorted_and_measured_inds = np.arange(len(tree_tuples))[mask][sorting]\n",
    "            tls_dbhs = msrmnt_triplets[:, 0]\n",
    "            manual_dbhs = msrmnt_triplets[:, 1]\n",
    "            ours_dbhs = msrmnt_triplets[:, 2]\n",
    "            fig_bias_std, ax_bias_std = plt.subplots(figsize=(10, 5))\n",
    "            ax_bias_std.plot(range(len(manual_dbhs)), manual_dbhs, label=\"manual\", marker='o', color=MANUAL_COLOR)\n",
    "            ax_bias_std.plot(range(len(tls_dbhs)), tls_dbhs, label=\"TLS\", marker='o', color=TLS_COLOR)\n",
    "            ax_bias_std.plot(range(len(ours_dbhs)), ours_dbhs, label=\"Ours\", marker='o', color=OURS_COLOR)\n",
    "            ax_bias_std.set_xticks(range(len(sorted_and_measured_inds)), sorted_and_measured_inds)\n",
    "            ax_bias_std.legend()\n",
    "        else:\n",
    "            print(tree_tuples[selection][\"ours_tree\"].reconstructed)\n",
    "            print(tree_tuples[selection][\"tls_tree\"].dbh, tree_tuples[selection][\"ours_tree\"].dbh) \n",
    "            o3d.visualization.draw_geometries(viz_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def non_nan(arr):\n",
    "    return arr[~np.isnan(arr)]\n",
    "\n",
    "\n",
    "path = \"/home/ori/git/digiforest_drs/trees/evaluation/accuracy\"\n",
    "suffix = \"\"\n",
    "plot_types = [\"mixed\", \"deciduous\", \"conifer\", \"all\"] # \"all\" has to be last\n",
    "num_datasets = 3\n",
    "\n",
    "\n",
    "# Load Reconstruction Results\n",
    "results = {}\n",
    "evaluations = {}\n",
    "\n",
    "for plot_type in plot_types:\n",
    "    results[plot_type] = []\n",
    "    evaluations[plot_type] = []\n",
    "    if \"all\" in plot_types:\n",
    "        plot_types_without_all = deepcopy(plot_types)\n",
    "        plot_types_without_all.remove(\"all\")\n",
    "    for i in range(num_datasets):\n",
    "        sub_evaluation = {}\n",
    "        if plot_type != \"all\":\n",
    "            sub_result_dbh = {\n",
    "                \"file_names\": [],\n",
    "                \"reco_times\": [],\n",
    "                \"ours_ids\": [],\n",
    "                \"manual_dbhs\": [],\n",
    "                \"tls_trees\": [],\n",
    "                \"ours_trees\": []\n",
    "            }\n",
    "            # load csv\n",
    "            filename = f\"{plot_type}\"\n",
    "            if suffix != \"\":\n",
    "                filename += f\"_{suffix}\"\n",
    "            filename += f\"_{i}.csv\"\n",
    "            with open(os.path.join(path, filename), \"r\") as file:\n",
    "                csv_reader = csv.DictReader(file)\n",
    "                for row in csv_reader:\n",
    "                    sub_result_dbh[\"file_names\"].append(row[\"file_name\"])\n",
    "                    if \"reco_time\" in row:\n",
    "                        sub_result_dbh[\"reco_times\"].append(float(row[\"reco_time\"]))\n",
    "                    sub_result_dbh[\"ours_ids\"].append(int(row[\"ours_id\"]))\n",
    "                    sub_result_dbh[\"manual_dbhs\"].append(float(row[\"manual_dbh\"]))\n",
    "                    \n",
    "                    tls_tree = Tree(int(row[\"file_name\"].split(\"_\")[1]))\n",
    "                    tls_centers_x = [float(x) for x in row[\"tls_centers_x\"].strip(\"[]\").split(\", \") if x != \"\"]\n",
    "                    tls_centers_y = [float(y) for y in row[\"tls_centers_y\"].strip(\"[]\").split(\", \") if y != \"\"]\n",
    "                    tls_centers_z = [float(z) for z in row[\"tls_centers_z\"].strip(\"[]\").split(\", \") if z != \"\"]\n",
    "                    tls_radii = [float(r) for r in row[\"tls_radii\"].strip(\"[]\").split(\", \") if r != \"\"]\n",
    "                    tls_tree.circles = [Circle(np.array([x, y, z]), r) for x, y, z, r in zip(tls_centers_x, tls_centers_y, tls_centers_z, tls_radii)]\n",
    "                    tls_dbh = float(row[\"tls_dbh\"])\n",
    "                    if not np.isnan(tls_dbh):\n",
    "                        tls_tree.dbh = tls_dbh\n",
    "                        tls_tree.reconstructed = True\n",
    "                    sub_result_dbh[\"tls_trees\"].append(tls_tree)\n",
    "                    \n",
    "                    ours_tree = Tree(int(row[\"ours_id\"]))\n",
    "                    ours_centers_x = [float(x) for x in row[\"ours_centers_x\"].strip(\"[]\").split(\", \") if x != \"\"]\n",
    "                    ours_centers_y = [float(y) for y in row[\"ours_centers_y\"].strip(\"[]\").split(\", \") if y != \"\"]\n",
    "                    ours_centers_z = [float(z) for z in row[\"ours_centers_z\"].strip(\"[]\").split(\", \") if z != \"\"]\n",
    "                    ours_radii = [float(r) for r in row[\"ours_radii\"].strip(\"[]\").split(\", \") if r != \"\"]\n",
    "                    ours_tree.circles = [Circle(np.array([x, y, z]), r) for x, y, z, r in zip(ours_centers_x, ours_centers_y, ours_centers_z, ours_radii)]\n",
    "                    ours_dbh = float(row[\"ours_dbh\"])\n",
    "                    if not np.isnan(ours_dbh):\n",
    "                        ours_tree.dbh = ours_dbh\n",
    "                        ours_tree.reconstructed = True\n",
    "                    sub_result_dbh[\"ours_trees\"].append(ours_tree)\n",
    "            \n",
    "            # apply global shift to fine-align ours_trees with tls_trees\n",
    "            errors = []\n",
    "            for tls_tree, ours_tree in zip(sub_result_dbh[\"tls_trees\"], sub_result_dbh[\"ours_trees\"]):\n",
    "                if ours_tree.reconstructed:\n",
    "                    tree_errors = []\n",
    "                    for c_ours in ours_tree.circles:\n",
    "                        c_tls = tls_tree.evaluate_at_height(c_ours.center[2])\n",
    "                        if c_tls:\n",
    "                            tree_errors.append(c_ours.center - c_tls.center)\n",
    "                    if len(tree_errors) > 0:\n",
    "                        errors.append(np.array(tree_errors))  \n",
    "            mean_errors = np.mean(np.vstack(errors), axis=0)\n",
    "            for ours_tree in sub_result_dbh[\"ours_trees\"]:\n",
    "                for circle in ours_tree.circles:\n",
    "                    circle.center -= mean_errors\n",
    "        elif plot_type == \"all\":\n",
    "            sub_result_dbh = {\n",
    "                \"file_names\": [item for sublist in [results[plot][i][\"file_names\"] for plot in plot_types_without_all] for item in sublist],\n",
    "                \"reco_times\": [item for sublist in [results[plot][i][\"reco_times\"] for plot in plot_types_without_all] for item in sublist],\n",
    "                \"ours_ids\": [item for sublist in [results[plot][i][\"ours_ids\"] for plot in plot_types_without_all] for item in sublist],\n",
    "                \"manual_dbhs\": [item for sublist in [results[plot][i][\"manual_dbhs\"] for plot in plot_types_without_all] for item in sublist],\n",
    "                \"tls_trees\": [item for sublist in [results[plot][i][\"tls_trees\"] for plot in plot_types_without_all] for item in sublist],\n",
    "                \"ours_trees\": [item for sublist in [results[plot][i][\"ours_trees\"] for plot in plot_types_without_all] for item in sublist]\n",
    "            }\n",
    "        # evaluate\n",
    "        if plot_type != \"all\":\n",
    "            ours_dbhs = np.array([tree.dbh  if tree.dbh else np.nan for tree in sub_result_dbh[\"ours_trees\"]])\n",
    "            tls_dbhs = np.array([tree.dbh  if tree.dbh else np.nan for tree in sub_result_dbh[\"tls_trees\"]])\n",
    "            manual_dbhs = np.array(sub_result_dbh[\"manual_dbhs\"])\n",
    "            sub_evaluation[\"dbh\"] = {\n",
    "                \"diffs\": {\n",
    "                    \"ours2tls\": (ours_dbhs - tls_dbhs),\n",
    "                    \"tls2manual\": (tls_dbhs - manual_dbhs),\n",
    "                    \"ours2manual\": (ours_dbhs - manual_dbhs),\n",
    "                },\n",
    "                \"ours\" : ours_dbhs,\n",
    "                \"tls\": tls_dbhs,\n",
    "                \"manual\": manual_dbhs\n",
    "            }\n",
    "            ours_centers = []; ours_diameters = []; tls_centers = []; tls_diameters = []\n",
    "            for tls_tree, ours_tree in zip(sub_result_dbh[\"tls_trees\"], sub_result_dbh[\"ours_trees\"]):\n",
    "                oc = []; od = []; tc = []; td = []\n",
    "                if ours_tree.reconstructed:\n",
    "                    for c_ours in ours_tree.circles:\n",
    "                        c_tls = tls_tree.evaluate_at_height(c_ours.center[2])\n",
    "                        if c_tls:\n",
    "                            tc.append(c_tls.center)\n",
    "                            td.append(2 * c_tls.radius)\n",
    "                            oc.append(c_ours.center)\n",
    "                            od.append(2 * c_ours.radius)\n",
    "                ours_centers.append(np.array(oc)); ours_diameters.append(np.array(od)); tls_centers.append(np.array(tc)); tls_diameters.append(np.array(td))\n",
    "            sub_evaluation[\"stem\"] = {\n",
    "                \"ours_centers\" : ours_centers,\n",
    "                \"ours_diameters\" : ours_diameters,\n",
    "                \"tls_centers\" : tls_centers,\n",
    "                \"tls_diameters\" : tls_diameters\n",
    "            }\n",
    "            sub_evaluation[\"height\"] = {\n",
    "                \"ours_heights\" : np.array([tree.circles[-1].center[2] - tree.circles[0].center[2]  if tree.reconstructed and len(tree.circles) > 2 else np.nan for tree in sub_result_dbh[\"ours_trees\"]]),\n",
    "                \"tls_heights\" : np.array([tree.circles[-1].center[2] - tree.circles[0].center[2] for tree in sub_result_dbh[\"tls_trees\"]])\n",
    "            }\n",
    "        elif plot_type == \"all\":\n",
    "            sub_evaluation[\"dbh\"] = {\n",
    "                \"diffs\": {\n",
    "                    \"ours2tls\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"diffs\"][\"ours2tls\"], evaluations[\"deciduous\"][i][\"dbh\"][\"diffs\"][\"ours2tls\"], evaluations[\"conifer\"][i][\"dbh\"][\"diffs\"][\"ours2tls\"]]),\n",
    "                    \"tls2manual\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"diffs\"][\"tls2manual\"], evaluations[\"deciduous\"][i][\"dbh\"][\"diffs\"][\"tls2manual\"], evaluations[\"conifer\"][i][\"dbh\"][\"diffs\"][\"tls2manual\"]]),\n",
    "                    \"ours2manual\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"diffs\"][\"ours2manual\"], evaluations[\"deciduous\"][i][\"dbh\"][\"diffs\"][\"ours2manual\"], evaluations[\"conifer\"][i][\"dbh\"][\"diffs\"][\"ours2manual\"]]),\n",
    "                },\n",
    "                \"ours\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"ours\"], evaluations[\"deciduous\"][i][\"dbh\"][\"ours\"], evaluations[\"conifer\"][i][\"dbh\"][\"ours\"]]),\n",
    "                \"tls\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"tls\"], evaluations[\"deciduous\"][i][\"dbh\"][\"tls\"], evaluations[\"conifer\"][i][\"dbh\"][\"tls\"]]),\n",
    "                \"manual\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"manual\"], evaluations[\"deciduous\"][i][\"dbh\"][\"manual\"], evaluations[\"conifer\"][i][\"dbh\"][\"manual\"]])\n",
    "            }\n",
    "            sub_evaluation[\"stem\"] = {\n",
    "                \"ours_centers\" : evaluations[\"mixed\"][i][\"stem\"][\"ours_centers\"] + evaluations[\"deciduous\"][i][\"stem\"][\"ours_centers\"] + evaluations[\"conifer\"][i][\"stem\"][\"ours_centers\"],\n",
    "                \"ours_diameters\" : evaluations[\"mixed\"][i][\"stem\"][\"ours_diameters\"] + evaluations[\"deciduous\"][i][\"stem\"][\"ours_diameters\"] + evaluations[\"conifer\"][i][\"stem\"][\"ours_diameters\"],\n",
    "                \"tls_centers\" : evaluations[\"mixed\"][i][\"stem\"][\"tls_centers\"] + evaluations[\"deciduous\"][i][\"stem\"][\"tls_centers\"] + evaluations[\"conifer\"][i][\"stem\"][\"tls_centers\"],\n",
    "                \"tls_diameters\" : evaluations[\"mixed\"][i][\"stem\"][\"tls_diameters\"] + evaluations[\"deciduous\"][i][\"stem\"][\"tls_diameters\"] + evaluations[\"conifer\"][i][\"stem\"][\"tls_diameters\"]\n",
    "            }\n",
    "            sub_evaluation[\"height\"] = {\n",
    "                \"ours_heights\" : np.hstack([evaluations[\"mixed\"][i][\"height\"][\"ours_heights\"], evaluations[\"deciduous\"][i][\"height\"][\"ours_heights\"], evaluations[\"conifer\"][i][\"height\"][\"ours_heights\"]]),\n",
    "                \"tls_heights\" : np.hstack([evaluations[\"mixed\"][i][\"height\"][\"tls_heights\"], evaluations[\"deciduous\"][i][\"height\"][\"tls_heights\"], evaluations[\"conifer\"][i][\"height\"][\"tls_heights\"]])\n",
    "            }\n",
    "        \n",
    "        # aggregate metrics\n",
    "        sub_evaluation[\"dbh\"][\"metrics\"] = {\n",
    "            \"RMSE_ours2tls\": np.sqrt(np.mean(np.square(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2tls\"])))),\n",
    "            \"RMSE_ours2manual\": np.sqrt(np.mean(np.square(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2manual\"])))),\n",
    "            \"RMSE_tls2manual\": np.sqrt(np.mean(np.square(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"tls2manual\"])))),\n",
    "            \"bias_ours2tls\": np.mean(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2tls\"])),\n",
    "            \"bias_ours2manual\": np.mean(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2manual\"])),\n",
    "            \"bias_tls2manual\": np.mean(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"tls2manual\"])),\n",
    "            \"std_ours2tls\": np.std(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2tls\"])),\n",
    "            \"std_ours2manual\": np.std(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2manual\"])),\n",
    "            \"std_tls2manual\": np.std(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"tls2manual\"])),\n",
    "            \"MAPE_ours2manual\": np.mean(non_nan(np.abs(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2manual\"]) / sub_evaluation[\"dbh\"][\"manual\"])) * 100,\n",
    "            \"MAPE_tls2manual\": np.mean(non_nan(np.abs(sub_evaluation[\"dbh\"][\"diffs\"][\"tls2manual\"]) / sub_evaluation[\"dbh\"][\"manual\"])) * 100,\n",
    "            \"MAPE_ours2tls\": np.mean(non_nan(np.abs(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2tls\"]) / sub_evaluation[\"dbh\"][\"tls\"])) * 100,\n",
    "        }\n",
    "        sub_evaluation[\"stem\"][\"metrics\"] = {\n",
    "            \"RMSE_centers\": 100 * np.sqrt(np.mean(np.square(np.hstack([np.linalg.norm(ours - tls, axis=1) for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_centers\"], sub_evaluation[\"stem\"][\"tls_centers\"]) if (ours - tls).shape[0] > 0])))),\n",
    "            \"RMSE_diameters\": 100 * np.sqrt(np.mean(np.square(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])))),\n",
    "            \"bias_centers\": 100 * np.mean(np.hstack([np.linalg.norm(ours - tls, axis=1) for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_centers\"], sub_evaluation[\"stem\"][\"tls_centers\"]) if (ours - tls).shape[0] > 0])),\n",
    "            \"bias_diameters\": 100 * np.mean(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])),\n",
    "            \"std_centers\": 100 * np.std(np.hstack([np.linalg.norm(ours - tls, axis=1) for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_centers\"], sub_evaluation[\"stem\"][\"tls_centers\"]) if (ours - tls).shape[0] > 0])),\n",
    "            \"std_diameters\": 100 * np.std(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])),\n",
    "            \"MAPE_diameters\": np.mean(np.abs(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])) / np.hstack([tls for tls in sub_evaluation[\"stem\"][\"tls_diameters\"]])) * 100,\n",
    "            \"RMSE_rel_diameters\": np.sqrt(np.mean(np.square(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])) / np.hstack(tls for tls in sub_evaluation[\"stem\"][\"tls_diameters\"]))) * 100,\n",
    "        }\n",
    "        sub_evaluation[\"height\"][\"metrics\"] = {\n",
    "            \"mean_ours\": np.mean(non_nan(sub_evaluation[\"height\"][\"ours_heights\"])),\n",
    "            \"mean_tls\": np.mean(non_nan(sub_evaluation[\"height\"][\"tls_heights\"])),\n",
    "        }\n",
    "        sub_evaluation[\"timing\"] = {\"metrics\": {\"reco_time\": 1000*np.mean(non_nan(np.array(sub_result_dbh[\"reco_times\"])))}}\n",
    "        \n",
    "        results[plot_type].append(sub_result_dbh)\n",
    "        evaluations[plot_type].append(sub_evaluation)\n",
    "\n",
    "\n",
    "\n",
    "metric_names = [\n",
    "    # \"dbh/RMSE_ours2manual\", \"dbh/RMSE_ours2tls\", \"dbh/RMSE_tls2manual\",\n",
    "    # \"\",\n",
    "    \"dbh/RMSE_ours2manual\", \"dbh/bias_ours2manual\", \"dbh/std_ours2manual\",\n",
    "    # \"\",\n",
    "    # \"dbh/bias_ours2tls\", \"dbh/bias_ours2manual\", \"dbh/bias_tls2manual\",\n",
    "    # \"\",\n",
    "    # \"dbh/MAPE_ours2manual\", \"dbh/MAPE_tls2manual\", \"dbh/MAPE_ours2tls\",\n",
    "    \"-\",\n",
    "    \"stem/RMSE_centers\", \"stem/bias_centers\", \"stem/std_centers\",\n",
    "    \"\",\n",
    "    \"stem/RMSE_diameters\", \"stem/bias_diameters\", \"stem/std_diameters\",\n",
    "    \"-\",\n",
    "    \"height/mean_ours\", \"height/mean_tls\",\n",
    "    \"-\",\n",
    "    \"timing/reco_time\"\n",
    "]\n",
    "\n",
    "pad_len_metric_name=max([len(metric_name) for metric_name in metric_names]) + 2\n",
    "pad_len_plot_type = max([len(plot_type) for plot_type in plot_types]) + 2\n",
    "header_string = f\"{'metric_name':<{pad_len_metric_name}}|\"\n",
    "for plot_type in plot_types:\n",
    "    header_string += f\"{plot_type:>{pad_len_plot_type}}\"\n",
    "print(f\"\\033[1m{header_string}\\033[0m\")\n",
    "print(\"-\"*len(header_string))\n",
    "for metric_name in metric_names:\n",
    "    if metric_name == \"\":\n",
    "        print()\n",
    "        continue\n",
    "    if metric_name == \"-\":\n",
    "        print(\"-\"*len(header_string))\n",
    "        continue\n",
    "    metric_first, metric_second = metric_name.split(\"/\")\n",
    "    plot_metrics = []\n",
    "    string = f\"{metric_name:<{pad_len_metric_name}}|\"\n",
    "    for plot_type in plot_types:\n",
    "        string += f\"{np.mean([e[metric_first]['metrics'][metric_second] for e in evaluations[plot_type]]):>{pad_len_plot_type}.2f}\"\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)\n",
    "# tls manual ours\n",
    "\n",
    "plot_config = {\n",
    "    \"mixed\": {\n",
    "        \"marker\": MIXED_MARKER,\n",
    "        \"marker_size\": 20,\n",
    "        \"title\": \"Mixed Plot\",\n",
    "    },\n",
    "    \"deciduous\": {\n",
    "        \"marker\": DECIDUOUS_MARKER,\n",
    "        \"marker_size\": 30,\n",
    "        \"title\":\"Deciduous Trees\",\n",
    "        },\n",
    "    \"conifer\": {\n",
    "        \"marker\": CONIFER_MARKER,\n",
    "        \"marker_size\": 15,\n",
    "        \"title\": \"Conifer Trees\",\n",
    "    },\n",
    "    \"all\": {\n",
    "        \"title\":\"All Trees\",\n",
    "    }\n",
    "}\n",
    "\n",
    "non_nan_row = lambda arr: arr[~np.isnan(arr).any(axis=1)]\n",
    "data_points = {\n",
    "    \"mixed\" : {\n",
    "        \"ours2tls\": non_nan_row(np.vstack([evaluations[\"mixed\"][i][\"dbh\"][\"ours\"], evaluations[\"mixed\"][i][\"dbh\"][\"tls\"]]).T),\n",
    "        \"ours2manual\": non_nan_row(np.vstack([evaluations[\"mixed\"][i][\"dbh\"][\"ours\"], evaluations[\"mixed\"][i][\"dbh\"][\"manual\"]]).T)\n",
    "    },\n",
    "    \"deciduous\" : {\n",
    "        \"ours2tls\": non_nan_row(np.vstack([evaluations[\"deciduous\"][i][\"dbh\"][\"ours\"], evaluations[\"deciduous\"][i][\"dbh\"][\"tls\"]]).T),\n",
    "        \"ours2manual\": non_nan_row(np.vstack([evaluations[\"deciduous\"][i][\"dbh\"][\"ours\"], evaluations[\"deciduous\"][i][\"dbh\"][\"manual\"]]).T)\n",
    "    },\n",
    "    \"conifer\" : {\n",
    "        \"ours2tls\": non_nan_row(np.vstack([evaluations[\"conifer\"][i][\"dbh\"][\"ours\"], evaluations[\"conifer\"][i][\"dbh\"][\"tls\"]]).T),\n",
    "        \"ours2manual\": non_nan_row(np.vstack([evaluations[\"conifer\"][i][\"dbh\"][\"ours\"], evaluations[\"conifer\"][i][\"dbh\"][\"manual\"]]).T)\n",
    "    }\n",
    "}\n",
    "data_points[\"mixed\"][\"min_radius\"] = data_points[\"mixed\"][\"ours2tls\"].min()\n",
    "data_points[\"mixed\"][\"max_radius\"] = data_points[\"mixed\"][\"ours2tls\"].max()\n",
    "data_points[\"deciduous\"][\"min_radius\"] = data_points[\"deciduous\"][\"ours2tls\"].min()\n",
    "data_points[\"deciduous\"][\"max_radius\"] = data_points[\"deciduous\"][\"ours2tls\"].max()\n",
    "data_points[\"conifer\"][\"min_radius\"] = data_points[\"conifer\"][\"ours2tls\"].min()\n",
    "data_points[\"conifer\"][\"max_radius\"] = data_points[\"conifer\"][\"ours2tls\"].max()\n",
    "data_points[\"all\"] = {\n",
    "    \"min_radius\": np.min([data_points[\"mixed\"][\"min_radius\"], data_points[\"deciduous\"][\"min_radius\"], data_points[\"conifer\"][\"min_radius\"]]),\n",
    "    \"max_radius\": np.max([data_points[\"mixed\"][\"max_radius\"], data_points[\"deciduous\"][\"max_radius\"], data_points[\"conifer\"][\"max_radius\"]]),\n",
    "}\n",
    "\n",
    "index = 2\n",
    "for plot_type in [\"mixed\", \"deciduous\", \"conifer\", \"all\"]:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3.3, 3.3))\n",
    "    fig.tight_layout()\n",
    "    min_radius = data_points[plot_type][\"min_radius\"]\n",
    "    max_radius = data_points[plot_type][\"max_radius\"]\n",
    "    ax.plot([min_radius, max_radius], [min_radius, max_radius], color=\"#6E6E6E\", linestyle='dashed', zorder=0)\n",
    "    ax.set_xlim(min_radius, max_radius)\n",
    "    ax.set_ylim(min_radius, max_radius)\n",
    "    ax.set_xticks(np.round(np.arange(min_radius, max_radius, 5)/5, 0)*5)\n",
    "    ax.set_yticks(np.round(np.arange(min_radius, max_radius, 5)/5, 0)*5)\n",
    "    if plot_type == \"all\":\n",
    "        ax.scatter(data_points[\"conifer\"][\"ours2tls\"][:, 0], data_points[\"conifer\"][\"ours2tls\"][:, 1], marker=plot_config[\"conifer\"][\"marker\"], s=plot_config[\"conifer\"][\"marker_size\"], color=TLS_COLOR, zorder=1)\n",
    "        ax.scatter(data_points[\"conifer\"][\"ours2manual\"][:, 0], data_points[\"conifer\"][\"ours2manual\"][:, 1], marker=plot_config[\"conifer\"][\"marker\"], s=plot_config[\"conifer\"][\"marker_size\"], color=MANUAL_COLOR, zorder=1)\n",
    "        ax.scatter(data_points[\"mixed\"][\"ours2tls\"][:, 0], data_points[\"mixed\"][\"ours2tls\"][:, 1], marker=plot_config[\"mixed\"][\"marker\"], s=plot_config[\"mixed\"][\"marker_size\"], color=TLS_COLOR, zorder=1)\n",
    "        ax.scatter(data_points[\"mixed\"][\"ours2manual\"][:, 0], data_points[\"mixed\"][\"ours2manual\"][:, 1], marker=plot_config[\"mixed\"][\"marker\"], s=plot_config[\"mixed\"][\"marker_size\"], color=MANUAL_COLOR, zorder=1)\n",
    "        ax.scatter(data_points[\"deciduous\"][\"ours2tls\"][:, 0], data_points[\"deciduous\"][\"ours2tls\"][:, 1], marker=plot_config[\"deciduous\"][\"marker\"], s=plot_config[\"deciduous\"][\"marker_size\"], color=TLS_COLOR, zorder=1)\n",
    "        ax.scatter(data_points[\"deciduous\"][\"ours2manual\"][:, 0], data_points[\"deciduous\"][\"ours2manual\"][:, 1], marker=plot_config[\"deciduous\"][\"marker\"], s=plot_config[\"deciduous\"][\"marker_size\"], color=MANUAL_COLOR, zorder=1)\n",
    "        legend_elements = [\n",
    "            matplotlib.lines.Line2D([0], [0], marker=MIXED_MARKER, color='w', markerfacecolor='k', markersize=10, label='Mixed'),\n",
    "            matplotlib.lines.Line2D([0], [0], marker=DECIDUOUS_MARKER, color='k', markerfacecolor='k', linestyle='', markersize=7, label='Deciduous'),\n",
    "            matplotlib.lines.Line2D([0], [0], marker=CONIFER_MARKER, color='w', markerfacecolor='k', markersize=10, label='Conifer'),\n",
    "            matplotlib.patches.Patch(color=TLS_COLOR, label='wrt. TLS'),\n",
    "            matplotlib.patches.Patch(color=MANUAL_COLOR, label='wrt. Manual'),\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='upper left')\n",
    "    else:\n",
    "        ax.scatter(data_points[plot_type][\"ours2tls\"][:, 0], data_points[plot_type][\"ours2tls\"][:, 1], marker=plot_config[plot_type][\"marker\"], s=plot_config[plot_type][\"marker_size\"], color=TLS_COLOR, zorder=1)\n",
    "        ax.scatter(data_points[plot_type][\"ours2manual\"][:, 0], data_points[plot_type][\"ours2manual\"][:, 1], marker=plot_config[plot_type][\"marker\"], s=plot_config[plot_type][\"marker_size\"], color=MANUAL_COLOR, zorder=1)\n",
    "    # ax.set_xlabel(\"Our DBH [cm]\")\n",
    "    # ax.set_ylabel(\"Reference DBH [cm]\")\n",
    "    ax.set_title(plot_config[plot_type][\"title\"])\n",
    "    fig.savefig(f\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/dbh_scatter_{plot_type}.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(viz_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "\n",
    "@widgets.interact(idx=widgets.IntSlider(min=0, max=len(centers_ours)-1, step=1, value=0))\n",
    "def update_slice_height(idx):\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(15, 8))\n",
    "    print(f\"Corr X: {correlation_x[idx]:.3f}, Corr Y: {correlation_y[idx]:.3f}, Corr Radius: {correlation_radius[idx]:.3f}\")\n",
    "    print(f\"Mean Error Dist: {mean_errors_dist[idx]*100:.3f} cm, Mean Error Radius: {mean_errors_radius[idx]*100:.3f} cm\")\n",
    "    ax[0].plot(range(len(centers_ours[idx])), [c[0] for c in centers_ours[idx]], label=\"Ours\", marker='o', color='r')\n",
    "    ax[0].plot(range(len(centers_gt[idx])), [c[0] for c in centers_gt[idx]], label=\"GT\", marker='o', color='g')\n",
    "    ax[0].set_title(\"X\")\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(range(len(centers_ours[idx])), [c[1] for c in centers_ours[idx]], label=\"Ours\", marker='o', color='r')\n",
    "    ax[1].plot(range(len(centers_gt[idx])), [c[1] for c in centers_gt[idx]], label=\"GT\", marker='o', color='g')\n",
    "    ax[1].set_title(\"Y\")\n",
    "    ax[1].legend()\n",
    "    ax[2].plot(range(len(radii_ours[idx])), radii_ours[idx], label=\"Ours\", marker='o', color='r')\n",
    "    ax[2].plot(range(len(radii_gt[idx])), radii_gt[idx], label=\"GT\", marker='o', color='g')\n",
    "    ax[2].set_title(\"Radius\")\n",
    "    ax[2].legend()\n",
    "    # fig.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(viz_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 02: Global Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "path = \"/home/ori/git/digiforest_drs/trees/evaluation/loop_closure_multiple\"\n",
    "\n",
    "with open(os.path.join(path, \"tree_manager_without_lc.pkl\"), \"rb\") as file:\n",
    "    tm_before = pickle.load(file)\n",
    "with open(os.path.join(path, \"tree_manager_with_lc.pkl\"), \"rb\") as file:\n",
    "    tm_after = pickle.load(file)\n",
    "\n",
    "if os.path.exists(os.path.join(path, \"tree_manager_without-with_lc_transform.txt\")):\n",
    "    with open(os.path.join(path, \"tree_manager_without-with_lc_transform.txt\"), \"r\") as file:\n",
    "        T = []\n",
    "        for row in file:\n",
    "            T.append([float(x) for x in row.split()])\n",
    "        T = np.array(T)\n",
    "        for tree in tm_before.trees:\n",
    "            tree.apply_transform(T[:3, 3], T[:3, :3])\n",
    "        # for tree in tm_after.trees:\n",
    "        #     tree.apply_transform(T[:3, 3], T[:3, :3])\n",
    "\n",
    "tuples_before, terrain_interpolator = load_tuples(\"/home/ori/datasets/digiforest_gt_prefor_C\", tm_before)\n",
    "tuples_after, terrain_interpolator = load_tuples(\"/home/ori/datasets/digiforest_gt_prefor_C\", tm_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "duration_threshold = 500\n",
    "for tuple in tqdm(tuples_before + tuples_after):\n",
    "    tuple[\"ours_tree\"].reconstruct3(max_radius=0.5)\n",
    "    tuple[\"ours_tree\"].compute_dbh(terrain_interpolator(tuple[\"ours_tree\"].axis[\"transform\"][:2, 3])[0])\n",
    "\n",
    "dbh_diffs_before = []; dbh_oldness_mask_before = []\n",
    "for tuple in tuples_before:\n",
    "    if \"manual_dbh\" not in tuple:\n",
    "        continue\n",
    "    if len(tuple[\"ours_tree\"].clusters) < 2:\n",
    "        continue\n",
    "    if tuple[\"ours_tree\"].dbh is not None:\n",
    "        dbh_diffs_before.append(tuple[\"ours_tree\"].dbh * 100 - tuple[\"manual_dbh\"])\n",
    "        time_stamps = [c[\"info\"][\"time_stamp\"].secs for c in tuple[\"ours_tree\"].clusters]\n",
    "        dbh_oldness_mask_before.append((max(time_stamps) - min(time_stamps)) > duration_threshold)\n",
    "dbh_diffs_after = []; dbh_oldness_mask_after = []\n",
    "for tuple in tuples_after:\n",
    "    if \"manual_dbh\" not in tuple:\n",
    "        continue\n",
    "    if len(tuple[\"ours_tree\"].clusters) < 2:\n",
    "        continue\n",
    "    if tuple[\"ours_tree\"].dbh is not None:\n",
    "        dbh_diffs_after.append(tuple[\"ours_tree\"].dbh * 100 - tuple[\"manual_dbh\"])\n",
    "        time_stamps = [c[\"info\"][\"time_stamp\"].secs for c in tuple[\"ours_tree\"].clusters]\n",
    "        dbh_oldness_mask_after.append((max(time_stamps) - min(time_stamps)) > duration_threshold)\n",
    "\n",
    "dbh_diffs_before = np.array(dbh_diffs_before); dbh_oldness_mask_before = np.array(dbh_oldness_mask_before)\n",
    "dbh_diffs_after = np.array(dbh_diffs_after); dbh_oldness_mask_after = np.array(dbh_oldness_mask_after)\n",
    "\n",
    "stem_diffs_dist_before = []; stem_diffs_dia_before = []; stem_oldness_mask_before = []\n",
    "for tuple in tuples_before:\n",
    "    if len(tuple[\"ours_tree\"].clusters) < 2:\n",
    "        continue\n",
    "    if not tuple[\"ours_tree\"].reconstructed:\n",
    "        continue\n",
    "    errors_center = []\n",
    "    errors_radius = []\n",
    "    for c_ours in tuple[\"ours_tree\"].circles:\n",
    "        c = tuple[\"tls_tree\"].evaluate_at_height(c_ours.center[2])\n",
    "        if c is not None:\n",
    "            errors_center.append(100 * (c.center - c_ours.center))\n",
    "            errors_radius.append(200 * (c.radius - c_ours.radius))\n",
    "    stem_diffs_dist_before.extend([np.linalg.norm(e) for e in errors_center])\n",
    "    stem_diffs_dia_before.extend(errors_radius)\n",
    "    time_stamps = [c[\"info\"][\"time_stamp\"].secs for c in tuple[\"ours_tree\"].clusters]\n",
    "    stem_oldness_mask_before.extend([(max(time_stamps) - min(time_stamps)) > duration_threshold] * len(errors_center))\n",
    "stem_diffs_dist_before = np.array(stem_diffs_dist_before); stem_diffs_dia_before = np.array(stem_diffs_dia_before); stem_oldness_mask_before = np.array(stem_oldness_mask_before)\n",
    "\n",
    "stem_diffs_dist_after = []; stem_diffs_dia_after = []; stem_oldness_mask_after = []\n",
    "for tuple in tuples_after:\n",
    "    if len(tuple[\"ours_tree\"].clusters) < 2:\n",
    "        continue\n",
    "    if not tuple[\"ours_tree\"].reconstructed:\n",
    "        continue\n",
    "    errors_center = []\n",
    "    errors_radius = []\n",
    "    for c_ours in tuple[\"ours_tree\"].circles:\n",
    "        c = tuple[\"tls_tree\"].evaluate_at_height(c_ours.center[2])\n",
    "        if c is not None:\n",
    "            errors_center.append(100 * (c.center - c_ours.center))\n",
    "            errors_radius.append(200 * (c.radius - c_ours.radius))\n",
    "    stem_diffs_dist_after.extend([np.linalg.norm(e) for e in errors_center])\n",
    "    stem_diffs_dia_after.extend(errors_radius)\n",
    "    time_stamps = [c[\"info\"][\"time_stamp\"].secs for c in tuple[\"ours_tree\"].clusters]\n",
    "    stem_oldness_mask_after.extend([(max(time_stamps) - min(time_stamps)) > duration_threshold] * len(errors_center))\n",
    "stem_diffs_dist_after = np.array(stem_diffs_dist_after); stem_diffs_dia_after = np.array(stem_diffs_dia_after); stem_oldness_mask_after = np.array(stem_oldness_mask_after)\n",
    "\n",
    "print(\"ALL TREES\")\n",
    "print(f\"DBH Before       | {np.sqrt(np.mean(np.square(dbh_diffs_before))):>10.3f} {np.mean(dbh_diffs_before):>10.3f} {np.std(dbh_diffs_before):>10.3f}\")\n",
    "print(f\"DBH After        | {np.sqrt(np.mean(np.square(dbh_diffs_after))):>10.3f} {np.mean(dbh_diffs_after):>10.3f} {np.std(dbh_diffs_after):>10.3f}\")\n",
    "print(\"\")\n",
    "print(f\"Stem Dist Before | {np.sqrt(np.mean(np.square(stem_diffs_dist_before))):>10.3f} {np.mean(stem_diffs_dist_before):>10.3f} {np.std(stem_diffs_dist_before):>10.3f}\")\n",
    "print(f\"Stem Dist After  | {np.sqrt(np.mean(np.square(stem_diffs_dist_after))):>10.3f} {np.mean(stem_diffs_dist_after):>10.3f} {np.std(stem_diffs_dist_after):>10.3f}\")\n",
    "print(\"\")\n",
    "print(f\"Stem Rad Before  | {np.sqrt(np.mean(np.square(stem_diffs_dia_before))):>10.3f} {np.mean(stem_diffs_dia_before):>10.3f} {np.std(stem_diffs_dia_before):>10.3f}\")\n",
    "print(f\"Stem Rad After   | {np.sqrt(np.mean(np.square(stem_diffs_dia_after))):>10.3f} {np.mean(stem_diffs_dia_after):>10.3f} {np.std(stem_diffs_dia_after):>10.3f}\")\n",
    "\n",
    "dbh_diffs_before = dbh_diffs_before[dbh_oldness_mask_before]\n",
    "dbh_diffs_after = dbh_diffs_after[dbh_oldness_mask_after]\n",
    "stem_diffs_dist_before = stem_diffs_dist_before[stem_oldness_mask_before]\n",
    "stem_diffs_dist_after = stem_diffs_dist_after[stem_oldness_mask_after]\n",
    "stem_diffs_dia_before = stem_diffs_dia_before[stem_oldness_mask_before]\n",
    "stem_diffs_dia_after = stem_diffs_dia_after[stem_oldness_mask_after]\n",
    "print()\n",
    "print(\"OLD TREES\")\n",
    "print(f\"DBH Before       | {np.sqrt(np.mean(np.square(dbh_diffs_before))):>10.3f} {np.mean(dbh_diffs_before):>10.3f} {np.std(dbh_diffs_before):>10.3f}\")\n",
    "print(f\"DBH After        | {np.sqrt(np.mean(np.square(dbh_diffs_after))):>10.3f} {np.mean(dbh_diffs_after):>10.3f} {np.std(dbh_diffs_after):>10.3f}\")\n",
    "print(\"\")\n",
    "print(f\"Stem Dist Before | {np.sqrt(np.mean(np.square(stem_diffs_dist_before))):>10.3f} {np.mean(stem_diffs_dist_before):>10.3f} {np.std(stem_diffs_dist_before):>10.3f}\")\n",
    "print(f\"Stem Dist After  | {np.sqrt(np.mean(np.square(stem_diffs_dist_after))):>10.3f} {np.mean(stem_diffs_dist_after):>10.3f} {np.std(stem_diffs_dist_after):>10.3f}\")\n",
    "print(\"\")\n",
    "print(f\"Stem Rad Before  | {np.sqrt(np.mean(np.square(stem_diffs_dia_before))):>10.3f} {np.mean(stem_diffs_dia_before):>10.3f} {np.std(stem_diffs_dia_before):>10.3f}\")\n",
    "print(f\"Stem Rad After   | {np.sqrt(np.mean(np.square(stem_diffs_dia_after))):>10.3f} {np.mean(stem_diffs_dia_after):>10.3f} {np.std(stem_diffs_dia_after):>10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = []\n",
    "for tuple in tuples_before:\n",
    "    time_stamps = [c[\"info\"][\"time_stamp\"].secs for c in tuple[\"ours_tree\"].clusters]\n",
    "    ages.append(max(time_stamps) - min(time_stamps))\n",
    "print(np.sort(ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index =  21\n",
    "slice_height = 4.2; slice_width = 0.2\n",
    "tree_before = tuples_before[index][\"ours_tree\"]\n",
    "for tuple in tuples_after:\n",
    "    if np.linalg.norm(tuple[\"ours_tree\"].axis[\"transform\"][:3, 3] - tree_before.axis[\"transform\"][:3, 3]) < 0.5:\n",
    "        tree_after = tuple[\"ours_tree\"]\n",
    "        break\n",
    "\n",
    "tree_before_points = [c[\"cloud\"].point.positions.numpy() @ c[\"info\"][\"T_sensor2map\"][:3, :3].T + c[\"info\"][\"T_sensor2map\"][:3, 3] for c in tree_before.clusters]\n",
    "tree_after_points = [c[\"cloud\"].point.positions.numpy() @ c[\"info\"][\"T_sensor2map\"][:3, :3].T + c[\"info\"][\"T_sensor2map\"][:3, 3] for c in tree_after.clusters]\n",
    "\n",
    "slice_height_before = terrain_interpolator(tree_before.axis[\"transform\"][:2, 3])[0] + slice_height\n",
    "slice_height_after = terrain_interpolator(tree_after.axis[\"transform\"][:2, 3])[0] + slice_height\n",
    "tree_before_slice = [c[np.logical_and(c[:, 2] > slice_height_before - slice_width / 2, c[:, 2] < slice_height_before + slice_width / 2)] for c in tree_before_points]\n",
    "tree_after_slice = [c[np.logical_and(c[:, 2] > slice_height_after - slice_width / 2, c[:, 2] < slice_height_after + slice_width / 2)] for c in tree_after_points]\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)  \n",
    "from matplotlib import pyplot as plt\n",
    "import colorsys\n",
    "all_points_before = np.vstack(tree_before_slice)\n",
    "xlims = [np.min(all_points_before[:, 0]), np.max(all_points_before[:, 0])]\n",
    "ylims = [np.min(all_points_before[:, 1]), np.max(all_points_before[:, 1])]\n",
    "\n",
    "fig_before, ax_before = plt.subplots(1, 1, figsize=(2, 2))\n",
    "fig_before.tight_layout()\n",
    "ax_before.set_aspect('equal')\n",
    "ax_before.set_xlim(*xlims)\n",
    "ax_before.set_ylim(*ylims)\n",
    "ax_before.axis('off')\n",
    "# ax_before.set_title(\"Without Loop Closure\")\n",
    "hues = np.linspace(0, 1, len(tree_before_slice) + 1)[:-1]\n",
    "for c, h in zip(tree_before_slice, hues):\n",
    "    ax_before.scatter(c[:, 0], c[:, 1], s=0.8, color=colorsys.hls_to_rgb(h, 0.45, 1))\n",
    "# fig_before.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/cloud_1_without_loop_closure.pdf\", bbox_inches='tight')\n",
    "\n",
    "fig_after, ax_after = plt.subplots(1, 1, figsize=(2, 2))\n",
    "fig_after.tight_layout()\n",
    "ax_after.set_aspect('equal')\n",
    "ax_after.axis('off')\n",
    "ax_after.set_xlim(*xlims)\n",
    "ax_after.set_ylim(*ylims)\n",
    "# ax_after.set_title(\"With Loop Closure\")\n",
    "for c, h in zip(tree_after_slice, hues):\n",
    "    ax_after.scatter(c[:, 0], c[:, 1], s=0.8, color=colorsys.hls_to_rgb(h, 0.45, 1))\n",
    "# fig_after.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/cloud_1_with_loop_closure.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 03: Ablations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "import colorsys\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# matplotlib.rc('text', usetex=False)\n",
    "\n",
    "# slice_height = 1.85; slice_width = 0.2; index = 9 # hough overestimates\n",
    "# slice_height = 4.3; slice_width = 0.2; index = 22, i_cluster = 2 # ransac overestimates\n",
    "# slice_height = 4.3; slice_width = 0.2; index = 22, i_cluster = 2 # ransac overestimates\n",
    "index = 28\n",
    "slice_height = 4.3\n",
    "slice_width = 0.2\n",
    "\n",
    "fig.tight_layout()\n",
    "def update_plot(slice_height, index, i_cluster):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    tree = datasets[\"conifer\"][\"tuples\"][index][\"ours_tree\"]\n",
    "    tls_circle = datasets[\"conifer\"][\"tuples\"][index][\"tls_tree\"].evaluate_at_height(slice_height)\n",
    "    hues = np.linspace(0, 1, len(tree.clusters) + 1)[:-1]\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(tls_circle.center[0] - 3 * tls_circle.radius, tls_circle.center[0] + 3 * tls_circle.radius)\n",
    "    ax.set_ylim(tls_circle.center[1] - 3 * tls_circle.radius, tls_circle.center[1] + 3 * tls_circle.radius)\n",
    "    # ax.set_ylim(-7, -5.5)\n",
    "    # ax.axis('off')\n",
    "    for i in range(len(tree.clusters)):\n",
    "    # for i in range(len(tree.clusters))[i_cluster:i_cluster+1]:\n",
    "        color = colorsys.hls_to_rgb(hues[i], 0.45, 1)\n",
    "        slice_points = tree.clusters[i][\"cloud\"].point.positions.numpy() @ tree.clusters[i][\"info\"][\"T_sensor2map\"][:3, :3].T + tree.clusters[i][\"info\"][\"T_sensor2map\"][:3, 3]\n",
    "        slice_points = slice_points[np.logical_and(slice_points[:, 2] > slice_height - slice_width / 2, slice_points[:, 2] < slice_height + slice_width / 2)]\n",
    "        if len(slice_points) == 0:\n",
    "            continue    \n",
    "        \n",
    "        # hough_code = '''circ_hough = Circle.from_cloud_hough(slice_points, max_radius=0.5)'''\n",
    "        # ransac_code = '''circ_ransac = Circle.from_cloud_ransac(slice_points, max_radius=0.5)'''\n",
    "        # ransahc_code = '''circ_ransahc = Circle.from_cloud_ransahc(slice_points, max_radius=0.5)'''\n",
    "        # # print(\"Hough Time:\", timeit.timeit(stmt=hough_code, globals=globals(), number=100))\n",
    "        # # print(\"RANSAC Time:\", timeit.timeit(stmt=ransac_code, globals=globals(), number=100))\n",
    "        # # print(\"RANSAHC Time:\", timeit.timeit(stmt=ransahc_code, globals=globals(), number=100))\n",
    "        # exec(hough_code)\n",
    "        # # exec(ransac_code)\n",
    "        # exec(ransahc_code)\n",
    "        circ_hough = Circle.from_cloud_hough(slice_points, max_radius=0.5)\n",
    "        circ_ransac = Circle.from_cloud_ransac(slice_points, max_radius=0.5)\n",
    "        circ_ransahc = Circle.from_cloud_ransahc(slice_points, max_radius=0.5)\n",
    "\n",
    "        ax.scatter(slice_points[:, 0], slice_points[:, 1], s=0.8, color=\"k\")\n",
    "        if circ_hough is not None:\n",
    "            ax.add_artist(plt.Circle(circ_hough.center[:2], circ_hough.radius, fill=False, color='r', label=\"Hough\"))\n",
    "        if circ_ransac is not None:\n",
    "            ax.add_artist(plt.Circle(circ_ransac.center[:2], circ_ransac.radius, fill=False, color='g', label=\"RANSAC\"))\n",
    "        if circ_ransahc is not None:\n",
    "            ax.add_artist(plt.Circle(circ_ransahc.center[:2], circ_ransahc.radius, fill=False, color='b', label=\"RANSAHC\"))\n",
    "    legend_elements = [\n",
    "        matplotlib.patches.Patch(label=\"Hough\", fill=None, edgecolor='r'),\n",
    "        matplotlib.patches.Patch(label=\"RANSAC\", fill=None, edgecolor='g'),\n",
    "        matplotlib.patches.Patch(label=\"RANSAHC\", fill=None, edgecolor='b'),\n",
    "        matplotlib.patches.Patch(label=\"TLS\", fill=None, edgecolor='k'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right')\n",
    "    ax.add_artist(plt.Circle(tls_circle.center[:2], tls_circle.radius, fill=False, color=\"y\", linestyle='dashed', label=\"TLS\", linewidth=2, zorder=1))\n",
    "    plt.show()\n",
    "\n",
    "slice_height_slider = widgets.FloatSlider(value=slice_height, min=0, max=10, step=0.01, description='Slice Height:')\n",
    "index_slider = widgets.IntSlider(value=index, min=0, max=len(datasets[\"conifer\"][\"tuples\"])-1, step=1, description='Index:')\n",
    "cluster_slider = widgets.IntSlider(value=0, min=0, max=len(datasets[\"conifer\"][\"tuples\"][index][\"ours_tree\"].clusters)-1, step=1, description='Cluster:')\n",
    "# save_button = widgets.Button(description='Save Graphic')\n",
    "# def save_graphic(button):\n",
    "#     fig.savefig('/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/ablation_#.pdf')\n",
    "# save_button.on_click(save_graphic)\n",
    "# display(save_button)\n",
    "widgets.interact(update_plot, slice_height=slice_height_slider, index=index_slider, i_cluster=cluster_slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "import colorsys\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# matplotlib.rc('text', usetex=False)\n",
    "\n",
    "# index = 28; slice_height = 4.3; slice_width = 0.2\n",
    "index = 17; slice_height = 3.9; slice_width = 0.2\n",
    "\n",
    "fig.tight_layout()\n",
    "fig_ransahc, ax_ransahc = plt.subplots(1, 1, figsize=(2.5, 2.5))\n",
    "fig_ransac, ax_ransac = plt.subplots(1, 1, figsize=(2.5, 2.5))\n",
    "fig_hough, ax_hough = plt.subplots(1, 1, figsize=(2.5, 2.5))\n",
    "\n",
    "tree = datasets[\"conifer\"][\"tuples\"][index][\"ours_tree\"]\n",
    "tls_circle = datasets[\"conifer\"][\"tuples\"][index][\"tls_tree\"].evaluate_at_height(slice_height)\n",
    "for ax in [ax_ransahc, ax_ransac, ax_hough]:\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(tls_circle.center[0] - 2 * tls_circle.radius, tls_circle.center[0] + 2 * tls_circle.radius)\n",
    "    ax.set_ylim(tls_circle.center[1] - 2 * tls_circle.radius, tls_circle.center[1] + 2 * tls_circle.radius)\n",
    "    ax.axis('off')\n",
    "    ax.add_artist(plt.Circle(tls_circle.center[:2], tls_circle.radius, fill=False, color=TLS_COLOR, linestyle='dashed', label=\"TLS\", linewidth=3, zorder=2))\n",
    "    \n",
    "for i in range(len(tree.clusters)):\n",
    "# for i in range(len(tree.clusters))[i_cluster:i_cluster+1]:\n",
    "    slice_points = tree.clusters[i][\"cloud\"].point.positions.numpy() @ tree.clusters[i][\"info\"][\"T_sensor2map\"][:3, :3].T + tree.clusters[i][\"info\"][\"T_sensor2map\"][:3, 3]\n",
    "    slice_points = slice_points[np.logical_and(slice_points[:, 2] > slice_height - slice_width / 2, slice_points[:, 2] < slice_height + slice_width / 2)]\n",
    "    if len(slice_points) == 0:\n",
    "        continue    \n",
    "    \n",
    "    # hough_code = '''circ_hough = Circle.from_cloud_hough(slice_points, max_radius=0.5)'''\n",
    "    # ransac_code = '''circ_ransac = Circle.from_cloud_ransac(slice_points, max_radius=0.5)'''\n",
    "    # ransahc_code = '''circ_ransahc = Circle.from_cloud_ransahc(slice_points, max_radius=0.5)'''\n",
    "    # # print(\"Hough Time:\", timeit.timeit(stmt=hough_code, globals=globals(), number=100))\n",
    "    # # print(\"RANSAC Time:\", timeit.timeit(stmt=ransac_code, globals=globals(), number=100))\n",
    "    # # print(\"RANSAHC Time:\", timeit.timeit(stmt=ransahc_code, globals=globals(), number=100))\n",
    "    # exec(hough_code)\n",
    "    # # exec(ransac_code)\n",
    "    # exec(ransahc_code)\n",
    "    circ_hough = Circle.from_cloud_hough(slice_points, max_radius=0.5)\n",
    "    circ_ransac = Circle.from_cloud_ransac(slice_points, max_radius=0.5)\n",
    "    circ_ransahc = Circle.from_cloud_ransahc(slice_points, max_radius=0.5)\n",
    "\n",
    "    for ax in [ax_hough, ax_ransac, ax_ransahc]:\n",
    "        ax.scatter(slice_points[:, 0], slice_points[:, 1], s=0.8, color=\"k\")\n",
    "    if circ_hough is not None:\n",
    "        ax_hough.add_artist(plt.Circle(circ_hough.center[:2], circ_hough.radius, fill=False, color='r', label=\"Hough\", zorder=1))\n",
    "    if circ_ransac is not None:\n",
    "        ax_ransac.add_artist(plt.Circle(circ_ransac.center[:2], circ_ransac.radius, fill=False, color='g', label=\"RANSAC\", zorder=1))\n",
    "    if circ_ransahc is not None:\n",
    "        ax_ransahc.add_artist(plt.Circle(circ_ransahc.center[:2], circ_ransahc.radius, fill=False, color='b', label=\"RANSAHC\", zorder=1))\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(label=\"Hough\", fill=None, edgecolor='r'),\n",
    "    matplotlib.patches.Patch(label=\"RANSAC\", fill=None, edgecolor='g'),\n",
    "    matplotlib.patches.Patch(label=\"RANSAHC\", fill=None, edgecolor='b'),\n",
    "    matplotlib.patches.Patch(label=\"TLS\", fill=None, edgecolor='k'),\n",
    "]\n",
    "# ax.legend(handles=legend_elements, loc='lower right')\n",
    "fig_ransahc.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/ablation_ransahc_2.pdf\", bbox_inches='tight')\n",
    "fig_ransac.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/ablation_ransac_2.pdf\", bbox_inches='tight')\n",
    "fig_hough.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/ablation_hough_2.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "results_dbh = []\n",
    "results_stem = []\n",
    "\n",
    "max_radii = {\"conifer\": 0.5, \"deciduous\": 0.15, \"mixed\": 0.25}\n",
    "for plot_type, dataset in datasets.items():\n",
    "    tree_tuples = dataset[\"tuples\"]\n",
    "    terrain_interpolator = dataset[\"terrain\"][\"interpolator\"]\n",
    "    for tree_tuple in tqdm(tree_tuples):\n",
    "        ground_elevation = terrain_interpolator(tree_tuple[\"ours_tree\"].axis[\"transform\"][:2, 3])[0]\n",
    "        tree_tuple[\"tls_tree\"].compute_dbh(ground_elevation)\n",
    "        sub_result_dbh = {\"tls_dbh\" : tree_tuple[\"tls_tree\"].dbh * 100 if tree_tuple[\"tls_tree\"].dbh is not None else np.nan, \"manual_dbh\" : tree_tuple[\"manual_dbh\"] if \"manual_dbh\" in tree_tuple else np.nan, \"ours_dbh\": []}\n",
    "        ours_tree : Tree = tree_tuple[\"ours_tree\"]\n",
    "        ours_tree_clusters = ours_tree.clusters\n",
    "        cluster_coverage_angles = np.array([(c[\"info\"][\"coverage\"][\"angle_from\"], c[\"info\"][\"coverage\"][\"angle_to\"]) for c in ours_tree_clusters])\n",
    "        sort_indices = np.argsort([angle_to - angle_from for angle_from, angle_to in cluster_coverage_angles])\n",
    "        for i_sort in range(1, len(sort_indices)):\n",
    "            ours_tree.clusters = [ours_tree_clusters[i_cluster] for i_cluster in sort_indices[:i_sort]]\n",
    "            coverage_angle = tm.compute_angle_coverage(cluster_coverage_angles[sort_indices[:i_sort]])\n",
    "            ours_tree.dbh = None\n",
    "            reco_success = ours_tree.reconstruct3(max_radius=max_radii[plot_type])\n",
    "            ours_tree.compute_dbh(ground_elevation)\n",
    "            if reco_success and ours_tree.dbh is not None:\n",
    "                reference = tree_tuple[\"manual_dbh\"] if \"manual_dbh\" in tree_tuple else tree_tuple[\"tls_tree\"].dbh * 100 if tree_tuple[\"tls_tree\"].dbh is not None else np.nan\n",
    "                sub_result_dbh[\"ours_dbh\"].append({\"coverage_angle\" : coverage_angle, \"dbh\" : ours_tree.dbh * 100})\n",
    "            else:\n",
    "                sub_result_dbh[\"ours_dbh\"].append({\"coverage_angle\" : coverage_angle, \"dbh\" : np.nan})\n",
    "            if reco_success:\n",
    "                results_stem.append({\"coverage\": [], \"distances\": [], \"radii\": []})\n",
    "                for c_ours in ours_tree.circles:\n",
    "                    c = tree_tuple[\"tls_tree\"].evaluate_at_height(c_ours.center[2])\n",
    "                    if c is not None:\n",
    "                        results_stem[-1][\"coverage\"].append(coverage_angle)\n",
    "                        results_stem[-1][\"distances\"].append(100 * np.linalg.norm(c.center - c_ours.center))\n",
    "                        results_stem[-1][\"radii\"].append(100 * (c.radius - c_ours.radius))\n",
    "                \n",
    "        ours_tree.clusters = ours_tree_clusters\n",
    "        results_dbh.append(sub_result_dbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)\n",
    "\n",
    "def smoothify(x, *y):\n",
    "    xnew = np.linspace(x.min(), x.max(), 1000)\n",
    "    y_new = []\n",
    "    for y_i in y:\n",
    "        spl = make_interp_spline(x, y_i, k=3)\n",
    "        y_new.append(spl(xnew))\n",
    "    return xnew, *y_new\n",
    "    \n",
    "# dbh\n",
    "color = MANUAL_COLOR\n",
    "coverage_angles = []\n",
    "errors_tls = []\n",
    "errors_manual = []\n",
    "for result in results_dbh:\n",
    "    coverage_angles.extend([np.rad2deg(r[\"coverage_angle\"]) for r in result[\"ours_dbh\"]])\n",
    "    errors_tls.extend([r[\"dbh\"] - result[\"tls_dbh\"] for r in result[\"ours_dbh\"]])\n",
    "    errors_manual.extend([r[\"dbh\"] - result[\"manual_dbh\"] for r in result[\"ours_dbh\"]])\n",
    "coverage_angles = np.array(coverage_angles)\n",
    "errors_tls = np.array(errors_tls)\n",
    "mask_tls = ~np.isnan(np.vstack([coverage_angles, errors_tls])).any(axis=0)\n",
    "mask_tls = np.logical_and(mask_tls, errors_tls < 10)\n",
    "errors_tls = errors_tls[mask_tls]\n",
    "coverage_angles_tls = coverage_angles[mask_tls]\n",
    "errors_manual = np.array(errors_manual)\n",
    "mask_manual = ~np.isnan(np.vstack([coverage_angles, errors_manual])).any(axis=0)    \n",
    "mask_manual = np.logical_and(mask_manual, errors_manual < 10)\n",
    "errors_manual = errors_manual[mask_manual]\n",
    "coverage_angles_manual = coverage_angles[mask_manual]\n",
    "coverage_angles = coverage_angles_manual\n",
    "errors = errors_manual\n",
    "\n",
    "# stem\n",
    "# color = TLS_COLOR\n",
    "# coverage_angles = np.array([np.rad2deg(ca) for result in results_stem for ca in result[\"coverage\"]])\n",
    "# # errors = np.array([d for result in results_stem for d in result[\"distances\"]])\n",
    "# errors = np.array([2*r for result in results_stem for r in result[\"radii\"]])\n",
    "# mask = np.abs(errors) < 10 # filter outliers\n",
    "# coverage_angles = coverage_angles[mask]\n",
    "# errors = errors[mask]\n",
    "\n",
    "\n",
    "means = []; stds = []; rmses = []\n",
    "num_buckets = 18\n",
    "bucket_boundaries = np.linspace(0, 360, num_buckets + 1, endpoint=True)\n",
    "bucket_centers = (bucket_boundaries[1:] + bucket_boundaries[:-1]) / 2\n",
    "bucket_mask = np.zeros(len(bucket_centers), dtype=bool)\n",
    "for i in range(len(bucket_boundaries) - 1):\n",
    "    mask = np.logical_and(coverage_angles > bucket_boundaries[i], coverage_angles <= bucket_boundaries[i + 1])\n",
    "    if mask.sum() > 3:\n",
    "        bucket = errors[mask]\n",
    "        means.append(np.mean(bucket))\n",
    "        rmses.append(np.sqrt(np.mean(bucket ** 2)))\n",
    "        stds.append(np.std(bucket))\n",
    "        bucket_mask[i] = True\n",
    "        \n",
    "bucket_centers = bucket_centers[bucket_mask]\n",
    "means = np.array(means); stds = np.array(stds); rmses = np.array(rmses)\n",
    "\n",
    "median_coverage_angle = np.median([c[\"info\"][\"coverage\"][\"angle_to\"] - c[\"info\"][\"coverage\"][\"angle_from\"] for dataset in datasets.values() for t in dataset[\"tuples\"] for c in t[\"ours_tree\"].clusters])\n",
    "print(np.rad2deg(median_coverage_angle))\n",
    "\n",
    "fig_rmse, ax_rmse = plt.subplots(1, 1, figsize=(4, 1.5))\n",
    "ax_rmse.bar(bucket_centers, rmses, width=360/num_buckets, label=\"Manual\", color=color, alpha=0.5, edgecolor=color)\n",
    "# ax_rmse.plot(bucket_centers, rmses, label=\"Manual\", marker=\"s\", color=color)\n",
    "# ax_rmse.scatter(bucket_centers, rmses, label=\"Manual\", marker=\"s\", s=20, color=color)\n",
    "# c = np.linalg.lstsq(np.vstack([bucket_centers, np.ones(len(bucket_centers))]).T, rmses, rcond=None)[0] # fit lsq line to rmses\n",
    "# ax_rmse.plot([0, 360], [c[1], c[0] * 360 + c[1]], color=color, linestyle='dashed')\n",
    "# ax_rmse.scatter(coverage_angles_manual, errors_manual, color=color, s=1)\n",
    "ax_rmse.set_xlabel(\"Coverage Angle [deg]\")\n",
    "ax_rmse.set_ylabel(\"RMSE [cm]\")\n",
    "ax_rmse.set_xticks([0, 90, 180, 270, 360])\n",
    "ax_rmse.set_xlim(0, 360)\n",
    "# ax_rmse.legend()\n",
    "# fig_rmse.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/coverage_ablation_rmse.pdf\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "fig_bias_std, ax_bias_std = plt.subplots(1, 1, figsize=(4, 1.5))\n",
    "ax_bias_std.plot([0, 360], [0, 0], color=\"#6E6E6E\", linestyle='dashed', zorder=0)\n",
    "bucket_centers, means, stds = smoothify(bucket_centers, means, stds)\n",
    "ax_bias_std.plot(bucket_centers, means, label=\"Manual\", color=color)\n",
    "ax_bias_std.fill_between(bucket_centers, means - stds, means + stds, color=color, alpha=0.3)\n",
    "ax_bias_std.set_xlabel(\"Coverage Angle [deg]\")\n",
    "ax_bias_std.set_ylabel(\"Error in DBH [cm]\")\n",
    "ax_bias_std.set_xticks([0, 90, 180, 270, 360])\n",
    "ax_bias_std.set_xlim(0, 360)\n",
    "# fig_bias_std.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/coverage_ablation_bias_std.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "filename = \"/home/ori/datasets/digiforest_gt_prefor_M/tree_manager.pkl\"\n",
    "with open(filename, \"rb\") as file:\n",
    "    tm = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "for tree in tm.trees:\n",
    "    for cluster in tree.clusters:\n",
    "        del cluster[\"cloud\"]\n",
    "\n",
    "with open(filename.replace(\".pkl\", \"_no_points.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(tm, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.trees[0].clusters[0][\"cloud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 04: Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_types = [\"coniferous\", \"deciduous\", \"mixed\"]\n",
    "tree_managers = {}\n",
    "results = {}\n",
    "for plot_type in plot_types:\n",
    "    with open(f\"/home/ori/git/digiforest_drs/trees/evaluation/timing/tree_manager_{plot_type}.pkl\", \"rb\") as file:\n",
    "        tree_managers[plot_type] = pickle.load(file)\n",
    "    sub_result_dbh = {}\n",
    "\n",
    "    timings = [{**tr[\"cw\"]._events, **tr[\"cwc\"]._events} for tr in tree_managers[plot_type].timing_results]\n",
    "\n",
    "    unique_time_stamps = np.sort(list(set([c[\"info\"][\"time_stamp\"].secs for tree in tree_managers[plot_type].trees for c in tree.clusters ])))\n",
    "    # time_stamp_tree_counts = np.sort([np.sum([time_stamp in [c[\"info\"][\"time_stamp\"].secs for c in tree.clusters] for tree in tree_managers[plot_type].trees]) for time_stamp in unique_time_stamps])\n",
    "\n",
    "    time_stamp_tree_counts = []\n",
    "    for i in range(len(unique_time_stamps)):\n",
    "        count = 0\n",
    "        for tree in tree_managers[plot_type].trees:\n",
    "            for ts in unique_time_stamps[:i]:\n",
    "                if ts in [c[\"info\"][\"time_stamp\"].secs for c in tree.clusters]:\n",
    "                    count += 1\n",
    "                    break\n",
    "        time_stamp_tree_counts.append(count)\n",
    "\n",
    "    for key in timings[0].keys():\n",
    "        if key in [\"cw\", \"cwc\", \"cwc/publishing_clustering\"]:\n",
    "            continue\n",
    "        times = [t[key]['time'] for t in timings[1:]]\n",
    "        # print(f\"{key:<30}: {np.mean(times):.3f} \\\\pm {np.std(times):.3f} s\")\n",
    "    all_times = np.array([t[\"cw\"][\"time\"] + t[\"cwc\"][\"time\"] for t in timings])\n",
    "    # print(f\"{'Total':<30}: {np.mean(all_times):.3f} \\\\pm {np.std(all_times):.3f} s\", \"\\n\")\n",
    "\n",
    "    durations = np.diff(unique_time_stamps)\n",
    "    results[plot_type] = {\n",
    "        \"unique_time_stamps\" : unique_time_stamps,\n",
    "        \"time_stamp_tree_counts\" : time_stamp_tree_counts,\n",
    "        \"durations\" : durations,\n",
    "        \"all_times\" : all_times,\n",
    "        \"timings\" : timings\n",
    "    }\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.5,1.5))\n",
    "\n",
    "plot_names = {\"coniferous\": \"Conifer\", \"deciduous\": \"Deciduous\", \"mixed\": \"Mixed\"}\n",
    "names = {\"cw/terrain\": \"Terrain\", \"cw/clustering\": \"Clustering\", \"cwc/tree_manager\": \"Tree Manager\", \"cwc/publishing_tree_manager\": \"Visualization\", \"cw/conversion\": \"Misc\"}\n",
    "colors = {\"cw/terrain\": \"#56b4e9\", \"cw/clustering\": \"#d55e00\", \"cwc/tree_manager\": \"#0173b2\", \"cwc/publishing_tree_manager\": \"#ece133\", \"cw/conversion\": \"#949494\"}\n",
    "payload_time_stamps = list(set([c[\"info\"][\"time_stamp\"].secs for plot_type in plot_types for tree in tree_managers[plot_type].trees for c in tree.clusters]))\n",
    "payload_ages = np.diff(np.sort(payload_time_stamps))\n",
    "payload_ages = payload_ages[payload_ages < 1000]\n",
    "mean_payload_age = np.mean(payload_ages)\n",
    "\n",
    "for i_pt, plot_type in enumerate(plot_types):\n",
    "    keys = [key for key in results[plot_type][\"timings\"][0].keys() if key not in [\"cw\", \"cwc\", \"cwc/publishing_clustering\"]]\n",
    "    keys = [\"cw/terrain\", \"cw/clustering\", \"cwc/tree_manager\", \"cwc/publishing_tree_manager\", \"cw/conversion\"]\n",
    "    runtimes = [np.mean([t[key][\"time\"] for t in results[plot_type][\"timings\"]]) for key in keys]\n",
    "    for i, (k, r) in enumerate(zip(keys, runtimes)):\n",
    "        # if k == \"cw/conversion\":\n",
    "        #     continue\n",
    "        ax.barh(len(plot_types) - i_pt, r, label=names[k], left=np.sum(runtimes[:i]), color=colors[k])\n",
    "    ax.errorbar(np.sum(runtimes), len(plot_types) - i_pt, xerr=np.std(results[plot_type][\"all_times\"]), color=\"k\", capsize=6, fmt=\".\")    \n",
    "ax.set_yticklabels([\"\"] + [plot_names[p] for p in plot_types][::-1]) \n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "ax.plot([mean_payload_age, mean_payload_age], [0.5, len(plot_types) + 0.5], color=\"k\", linestyle=\"dashed\", label=\"Mean Payload\\nCollection Time\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "ax.legend(by_label.values(), by_label.keys(), ncol=1, bbox_to_anchor=(1.0, 1.05))\n",
    "all_all_times = np.concatenate([results[plot_type][\"all_times\"] for plot_type in plot_types])\n",
    "fig.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/timings.pdf\", bbox_inches='tight')\n",
    "# print(\"all\")\n",
    "# print (f\"{'Total':<30}: {np.mean(all_all_times):.3f} \\\\pm {np.std(all_all_times):.3f} s\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)\n",
    "from scipy.spatial import cKDTree\n",
    "# Define the sliders\n",
    "i_cluster_slider = widgets.IntSlider(min=0, max=len(tree.clusters)-1, step=1, value=11, description='Cluster Index:')\n",
    "i_tree_slider = widgets.IntSlider(min=0, max=len(datasets[\"conifer\"][\"tuples\"])-1, step=1, value=3, description='Tree Index:')\n",
    "slice_height_slider = widgets.FloatSlider(min=0, max=1, step=0.1, value=slice_height, description='Slice Height:')\n",
    "slice_width_slider = widgets.FloatSlider(min=0, max=1, step=0.1, value=slice_width, description='Slice Width:')\n",
    "\n",
    "# Define the update function\n",
    "# make 3d plot\n",
    "def update_plot(i_cluster, i_tree, slice_height, slice_width):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 2.5), subplot_kw={'projection':'3d'})\n",
    "    fig.tight_layout()\n",
    "    tree = datasets[\"conifer\"][\"tuples\"][i_tree][\"ours_tree\"]\n",
    "    slice_points = []\n",
    "    # for i_cluster in range(len(tree.clusters))[2:5]:\n",
    "    for i_cluster in [i_cluster]:\n",
    "        sp = tree.clusters[i_cluster][\"cloud\"].point.positions.numpy() @ tree.clusters[i_cluster][\"info\"][\"T_sensor2map\"][:3, :3].T + tree.clusters[i_cluster][\"info\"][\"T_sensor2map\"][:3, 3]\n",
    "        sp = sp[np.logical_and(sp[:, 2] > slice_height - slice_width / 2, sp[:, 2] < slice_height + slice_width / 2)]\n",
    "        slice_points.append(sp)\n",
    "    slice_points = np.vstack(slice_points)[:, :2]\n",
    "    circle_actual = Circle.from_cloud_ransahc(slice_points, max_radius=0.5)\n",
    "\n",
    "    indices = ((1 - np.random.rand(2000, len(slice_points)))).argpartition(3, axis=1)[:, :3]\n",
    "    circles = Circle.from_3_2d_points(slice_points[indices])\n",
    "    \n",
    "    circles = circles[np.logical_and(\n",
    "        np.linalg.norm(circles[:, :2] - circle_actual.center[:2], axis=1) < 0.3,\n",
    "        np.abs(circles[:, 2] - circle_actual.radius) < 0.5\n",
    "    )]\n",
    "    \n",
    "    color_mask = np.zeros(len(circles), dtype=bool)\n",
    "    query_circles = circles.copy()\n",
    "    query_circles[:, 2] *= 2\n",
    "    kdtree = cKDTree(query_circles)\n",
    "    neighbors = kdtree.query_ball_tree(kdtree, r=0.05)\n",
    "    best_index = neighbors.index(max(neighbors, key=len))\n",
    "    best_circle_inds = neighbors[best_index] + [best_index]\n",
    "    color_mask[best_circle_inds] = True\n",
    "    \n",
    "    ax.grid(alpha=0.01)\n",
    "    ax.set_box_aspect((np.ptp(circles[:, 0]), np.ptp(circles[:, 1]), 1.5*np.ptp(circles[:, 2])))\n",
    "    ax.set_xticks(np.round(np.arange(np.min(circles[:, 0]), np.max(circles[:, 0]), 0.2), 1))\n",
    "    ax.set_yticks(np.round(np.arange(np.min(circles[:, 1]), np.max(circles[:, 1]), 0.2), 1))\n",
    "    ax.set_zticks(np.round(np.arange(np.min(circles[:, 2]), np.max(circles[:, 2]), 0.2), 1))\n",
    "    ax.tick_params(axis='x', which='major', labelsize=6, pad=-5)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=6, pad=-5)\n",
    "    ax.tick_params(axis='z', which='major', labelsize=6, pad=0)\n",
    "    ax.set_xlabel(\"y\",labelpad=-13); ax.set_ylabel(\"x\",labelpad=-11); ax.set_zlabel(\"r\",labelpad=0)\n",
    "    \n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "    colors = [\"r\" if cm else \"k\" for cm in color_mask]\n",
    "    ax.scatter(circles[:, 0], circles[:, 1], circles[:, 2], s=0.5, color=colors)\n",
    "    # change view angle\n",
    "    ax.view_init(10, -60)\n",
    "    # fig.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/hough_scatter.pdf\", bbox_inches='tight')\n",
    "\n",
    "# Display the sliders and plot\n",
    "display(i_cluster_slider, i_tree_slider, slice_height_slider, slice_width_slider)\n",
    "update_plot(i_cluster_slider.value, i_tree_slider.value, slice_height_slider.value, slice_width_slider.value)\n",
    "\n",
    "# Define the slider callbacks\n",
    "def i_cluster_slider_callback(change):\n",
    "    update_plot(change.new, i_tree_slider.value, slice_height_slider.value, slice_width_slider.value)\n",
    "\n",
    "def i_tree_slider_callback(change):\n",
    "    update_plot(i_cluster_slider.value, change.new, slice_height_slider.value, slice_width_slider.value)\n",
    "\n",
    "def slice_height_slider_callback(change):\n",
    "    update_plot(i_cluster_slider.value, i_tree_slider.value, change.new, slice_width_slider.value)\n",
    "\n",
    "def slice_width_slider_callback(change):\n",
    "    update_plot(i_cluster_slider.value, i_tree_slider.value, slice_height_slider.value, change.new)\n",
    "\n",
    "# Attach the callbacks to the sliders\n",
    "i_cluster_slider.observe(i_cluster_slider_callback, names='value')\n",
    "i_tree_slider.observe(i_tree_slider_callback, names='value')\n",
    "slice_height_slider.observe(slice_height_slider_callback, names='value')\n",
    "slice_width_slider.observe(slice_width_slider_callback, names='value')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digiforest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
