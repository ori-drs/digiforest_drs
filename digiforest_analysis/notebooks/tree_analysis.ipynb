{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets # for interactive sliders\n",
    "import pickle\n",
    "from timeit import timeit\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "from digiforest_analysis.utils.timing import Timer\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"/home/ori/git/realtime-trees/single_trees/clustering_2/\"\n",
    "SLICE_HEIGHT = 0.5\n",
    "TREE_ID = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = DATASET_DIR + \"tree\" + str(TREE_ID).zfill(3) + \".pkl\"\n",
    "with open(file_name, 'rb') as file:\n",
    "    cluster = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_height = 2.0\n",
    "slice_thickness = 2.0\n",
    "cloud = cluster['cloud'].point.positions.numpy()\n",
    "slice = cloud[np.logical_and(cloud[:, 2] >= slice_height - slice_thickness / 2, cloud[:, 2] < slice_height + slice_thickness / 2,)][:, :2]\n",
    "print(len(slice))\n",
    "\n",
    "# timing_hough = timeit(\"Circle.from_cloud_hough(slice)\", \"from __main__ import Circle, slice\", number=1000)\n",
    "# print(f\"Hough algo took {timing_hough:.3f} ms\")\n",
    "# timing_new = timeit(\"new_hough(slice)\", \"from __main__ import new_hough, slice\", number=1000)\n",
    "# print(f\"New algo took {timing_new:.3f} ms\")\n",
    "\n",
    "with timer(\"OLD\"):\n",
    "    circ_hough = Circle.from_cloud_hough(slice)\n",
    "with timer(\"NEW\"):\n",
    "    # circ_new, circles = Circle.from_cloud_ransahc(slice, min_radius=0.05, max_radius=0.5, sampling=\"weighted\", max_points=100)\n",
    "    circ_new = Circle.from_cloud_ransahc(slice, min_radius=0.05, max_radius=0.5, sampling=\"weighted\", max_circles=500)\n",
    "\n",
    "print(timer)\n",
    "plt.scatter(slice[:, 0], slice[:, 1], s=5)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "# plot circle\n",
    "plt.gca().add_artist(plt.Circle((circ_hough.x, circ_hough.y), circ_hough.radius, color='r', fill=False))\n",
    "plt.gca().add_artist(plt.Circle((circ_new.x, circ_new.y), circ_new.radius, color='g', fill=False))\n",
    "# plt.scatter(circles[:, 0], circles[:, 1], s=5, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import pickle, os\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "# %matplotlib notebook\n",
    "\n",
    "path = \"/home/ori/git/digiforest_drs/trees/logs/raw\"\n",
    "TREE_ID = 12\n",
    "tree_path = os.path.join(path, f\"tree{TREE_ID:03d}.pkl\")\n",
    "with open(tree_path, 'rb') as file:\n",
    "    tree : Tree = pickle.load(file)\n",
    "\n",
    "def align_clouds(clusters):\n",
    "    trafos_map = [c[\"info\"][\"T_sensor2map\"] @ c[\"info\"][\"axis\"][\"transform\"] for c in clusters]\n",
    "    clouds_map = [c[\"cloud\"].point.positions.numpy() @ c[\"info\"][\"T_sensor2map\"][:3, :3].T + c[\"info\"][\"T_sensor2map\"][:3, 3] for c in clusters]\n",
    "    mean_position = np.mean([t[:3, 3] for t in trafos_map], axis=0)\n",
    "    deltas = [t[:3, 3] - mean_position for t in trafos_map]\n",
    "    deltas = [np.array([d[0], d[1], 0]) for d in deltas]\n",
    "    return [c - d for c, d in zip(clouds_map, deltas)]\n",
    "\n",
    "\n",
    "\n",
    "# # make 3d plot of clusters in different colors\n",
    "# fig = go.Figure()\n",
    "# for cluster in tree.clusters:\n",
    "#     cloud = cluster['cloud'].point.positions.numpy()\n",
    "#     transform = cluster['info']['T_sensor2map']\n",
    "#     cloud = cloud @ transform[:3, :3].T + transform[:3, 3]\n",
    "#     fig.add_trace(go.Scatter3d(x=cloud[:, 0], y=cloud[:, 1], z=cloud[:, 2], mode='markers', marker=dict(size=1)))\n",
    "# fig.show()\n",
    "\n",
    "# make a 2d plot with a slider that changes the height of the slice\n",
    "clouds = [\n",
    "    cluster['cloud'].point.positions.numpy() @ cluster['info']['T_sensor2map'][:3, :3].T + cluster['info']['T_sensor2map'][:3, 3]\n",
    "    for cluster in tree.clusters\n",
    "]\n",
    "clouds_aligned = align_clouds(tree.clusters)\n",
    "cloud_merged = np.concatenate(clouds, axis=0)\n",
    "cloud_aligned_merged = np.concatenate(clouds_aligned, axis=0)\n",
    "# cloud_aligned_merged = tree.points\n",
    "hues = np.linspace(0, 1, len(clouds) + 1)[:len(clouds)]\n",
    "colors = [colorsys.hsv_to_rgb(h, 1, 1) for h in hues]\n",
    "\n",
    "slice_thickness = 0.2\n",
    "# min and max width and height are 10th and 90 th percentiles\n",
    "min_width, max_width = np.percentile(cloud_merged[:, 0], [2, 98])\n",
    "min_height, max_height = np.percentile(cloud_merged[:, 1], [2, 98])\n",
    "@widgets.interact(height=widgets.FloatSlider(min=cloud_merged[:, 2].min(), max=cloud_merged[:, 2].max(), step=0.3, value=0.0))\n",
    "def update_slice_height(height):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    for a in ax:\n",
    "        a.set_aspect('equal', adjustable='box')\n",
    "        a.set_xlim(min_width, max_width)\n",
    "        a.set_ylim(min_height, max_height)\n",
    "    for cloud, color in zip(clouds, colors):\n",
    "        slice = cloud[np.logical_and(cloud[:, 2] >= height - slice_thickness / 2, cloud[:, 2] < height + slice_thickness / 2,)][:, :2]\n",
    "        ax[0].scatter(slice[:, 0], slice[:, 1], s=1, color=color)\n",
    "    for cloud, color in zip(clouds_aligned, colors):\n",
    "        slice = cloud[np.logical_and(cloud[:, 2] >= height - slice_thickness / 2, cloud[:, 2] < height + slice_thickness / 2,)][:, :2]\n",
    "        ax[1].scatter(slice[:, 0], slice[:, 1], s=1, color=color)\n",
    "    slice_merged = cloud_merged[np.logical_and(cloud_merged[:, 2] >= height - slice_thickness / 2, cloud_merged[:, 2] < height + slice_thickness / 2,)][:, :2]\n",
    "    slice_aligned_merged = cloud_aligned_merged[np.logical_and(cloud_aligned_merged[:, 2] >= height - slice_thickness / 2, cloud_aligned_merged[:, 2] < height + slice_thickness / 2,)][:, :2]\n",
    "    ax[2].scatter(slice_aligned_merged[:, 0], slice_aligned_merged[:, 1], s=1, color='k')\n",
    "    # fit hough circle\n",
    "    center_region = Circle(tree.axis[\"transform\"][:3, 3], tree.axis[\"radius\"])\n",
    "    min_radius = 0.5 * tree.axis[\"radius\"]\n",
    "    max_radius = 1.5 * tree.axis[\"radius\"]\n",
    "    circ_hough = Circle.from_cloud_hough(slice_merged, min_radius=0.05, max_radius=0.5)\n",
    "    circ_hough_aligned = Circle.from_cloud_hough(slice_aligned_merged, min_radius=0.05, max_radius=0.5)\n",
    "    circ_ransahc = Circle.from_cloud_ransahc(slice_merged, min_radius=min_radius, max_radius=max_radius, center_region=center_region)\n",
    "    circ_ransahc_aligned = Circle.from_cloud_ransahc(slice_aligned_merged, min_radius=min_radius, max_radius=max_radius, center_region=center_region)\n",
    "    ax[0].add_artist(plt.Circle((circ_hough.x, circ_hough.y), circ_hough.radius, color='r', fill=False, linewidth=2))\n",
    "    ax[0].add_artist(plt.Circle((circ_ransahc.x, circ_ransahc.y), circ_ransahc.radius, color='g', fill=False, linewidth=2))\n",
    "    ax[2].add_artist(plt.Circle((circ_hough_aligned.x, circ_hough_aligned.y), circ_hough_aligned.radius, color='r', fill=False, linewidth=2))\n",
    "    ax[2].add_artist(plt.Circle((circ_ransahc_aligned.x, circ_ransahc_aligned.y), circ_ransahc_aligned.radius, color='g', fill=False, linewidth=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import colorsys\n",
    "import pickle, os\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "\n",
    "path = \"/home/ori/git/digiforest_drs/trees/logs/raw\"\n",
    "TREE_ID = 50\n",
    "tree_path = os.path.join(path, f\"tree{TREE_ID:03d}.pkl\")\n",
    "with open(tree_path, 'rb') as file:\n",
    "    tree : Tree = pickle.load(file) \n",
    "\n",
    "# clouds = [cluster['cloud'].transform(cluster['info']['T_sensor2map']).point.positions.numpy() for cluster in tree.clusters]\n",
    "clouds = [cluster['cloud'].point.positions.numpy() @ cluster['info']['T_sensor2map'][:3, :3].T + cluster['info']['T_sensor2map'][:3, 3]for cluster in tree.clusters]\n",
    "hues = np.linspace(0, 1, len(clouds) + 1) [:len(clouds)]\n",
    "colors = np.concatenate([np.array([[colorsys.hls_to_rgb(h, 0.6, 1)]]*len(c)) for h, c in zip(hues, clouds)]).squeeze()\n",
    "# for cluster in tree.clusters:\n",
    "#     axis_trafo = cluster[\"info\"]['T_sensor2map'] @ cluster[\"info\"][\"axis\"][\"transform\"]\n",
    "#     circle_lower = Circle(axis_trafo[:3, 3], cluster[\"info\"][\"axis\"][\"radius\"], axis_trafo[:3, 2])\n",
    "#     circle_lower = Circle(axis_trafo[:3, 3] + axis_trafo[:3, 2] * cluster)\n",
    "#     verts, tris = circle_lower.generate_cone_frustum_mesh(circle_upper)\n",
    "#     verts_vec = o3d.utility.Vector3dVector(verts)\n",
    "#     tris_vec = o3d.utility.Vector3iVector(\n",
    "#         np.concatenate((tris, np.flip(tris, axis=1)), axis=0)\n",
    "#     )\n",
    "#     terrain_mesh = o3d.geometry.TriangleMesh(verts_vec, tris_vec)\n",
    "# raise ValueError\n",
    "cloud_aligned = tree.points\n",
    "o3d_cloud = o3d.t.geometry.PointCloud(np.vstack(clouds))\n",
    "o3d_cloud_aligned = o3d.t.geometry.PointCloud(cloud_aligned)\n",
    "o3d_cloud.point.colors = colors\n",
    "o3d_cloud_aligned.point.colors = colors\n",
    "\n",
    "# min_height = 5\n",
    "# max_height = 6\n",
    "# mask = np.logical_and(o3d_cloud.point.positions.numpy()[:, 2] > min_height, o3d_cloud.point.positions.numpy()[:, 2] < max_height)\n",
    "# o3d_cloud = o3d_cloud.select_by_mask(mask)\n",
    "# mask = np.logical_and(o3d_cloud_aligned.point.positions.numpy()[:, 2] > min_height, o3d_cloud_aligned.point.positions.numpy()[:, 2] < max_height)\n",
    "# o3d_cloud_aligned = o3d_cloud_aligned.select_by_mask(mask)\n",
    "\n",
    "aligned_cloud_flag = False\n",
    "\n",
    "def toggle_point_cloud(vis):\n",
    "    global aligned_cloud_flag\n",
    "    current_view = vis.get_view_control().convert_to_pinhole_camera_parameters()\n",
    "    \n",
    "    if aligned_cloud_flag:\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(o3d_cloud_aligned.to_legacy())\n",
    "        aligned_cloud_flag = False\n",
    "        print(\"Showing Aligned Cloud\")\n",
    "    else:\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(o3d_cloud.to_legacy())\n",
    "        print(\"Showing Non-Aligned Cloud\")\n",
    "        aligned_cloud_flag = True\n",
    "    vis.get_view_control().convert_from_pinhole_camera_parameters(current_view, True)\n",
    "\n",
    "visualizer = o3d.visualization.VisualizerWithKeyCallback()\n",
    "visualizer.create_window()\n",
    "visualizer.add_geometry(o3d_cloud.to_legacy())\n",
    "visualizer.register_key_callback(ord(\"C\"), toggle_point_cloud)\n",
    "visualizer.run()\n",
    "visualizer.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os, time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "\n",
    "path = \"/home/ori/git/digiforest_drs/trees/logs/raw\"\n",
    "TREE_ID = 63\n",
    "tree_path = os.path.join(path, f\"tree{TREE_ID:03d}.pkl\")\n",
    "with open(tree_path, 'rb') as file:\n",
    "    tree : Tree = pickle.load(file) \n",
    "TIME = time.perf_counter()\n",
    "print(tree.reconstruct2(max_radius_deviation=100))\n",
    "print(time.perf_counter() - TIME)   \n",
    "\n",
    "# # DEBUG inside tree.reconstruct2\n",
    "# from matplotlib import pyplot as plt\n",
    "# import matplotlib\n",
    "# import numpy as np\n",
    "# import colorsys\n",
    "# matplotlib.use(\"TKagg\")\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.set_xlabel(\"x\")\n",
    "# ax.set_ylabel(\"y\")\n",
    "# ax.set_xlim((-0.5, 0.5))\n",
    "# ax.set_ylim((-0.5, 0.4))\n",
    "# ax.set_title(\"Averaging of individual Payload Clouds\")\n",
    "# ax.set_aspect('equal', adjustable='box')\n",
    "# hues = np.linspace(0, 1, len(ransahc_circles) + 1)[:len(ransahc_circles)]\n",
    "# colors = [list(colorsys.hls_to_rgb(hue, 0.55, 0.8)) for hue in hues]\n",
    "# for points, circle, color in zip(debug_slice_points, ransahc_circles, colors):\n",
    "#     ax.scatter(points[:, 0], points[:, 1], c=[color]*len(points), s=2)\n",
    "#     ax.add_artist(plt.Circle((circle.x, circle.y), circle.radius, color=color, fill=False))\n",
    "# ax.add_artist(plt.Circle((circle.x, circle.y), circle.radius, color=\"g\", linestyle='dashed', fill=False, linewidth=5))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digiforest_analysis_ros.src.digiforest_analysis_ros.forest_analysis import TreeManager\n",
    "import pickle, os\n",
    "\n",
    "path = \"/home/ori/git/digiforest_drs/trees/logs/raw_sar_exp03\"\n",
    "tm = TreeManager()\n",
    "trees = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".pkl\"):\n",
    "        with open(os.path.join(path, file), 'rb') as f:\n",
    "            tree = pickle.load(f)\n",
    "            trees.append(tree)\n",
    "tm.trees = trees\n",
    "tm.num_trees = len(trees)\n",
    "# write back pickle of tm\n",
    "with open(os.path.join(path, \"tree_manager.pkl\"), 'wb') as f:\n",
    "    pickle.dump(tm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import laspy\n",
    "import csv, os, pickle\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Error)\n",
    "\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "from digiforest_analysis_ros.forest_analysis import TreeManager\n",
    "from digiforest_analysis.tasks.terrain_fitting import TerrainFitting\n",
    "from digiforest_analysis.utils.distances import distance_line_to_line\n",
    "\n",
    "datasets = {\"mixed\": {}, \"deciduous\": {}, \"conifer\": {}}\n",
    "paths = {\n",
    "    \"mixed\": \"/home/ori/datasets/digiforest_gt_prefor_M\",\n",
    "    \"deciduous\": \"/home/ori/datasets/digiforest_gt_prefor_D\",\n",
    "    \"conifer\": \"/home/ori/datasets/digiforest_gt_prefor_C\"\n",
    "}\n",
    "OURS_COLOR = \"#2639DF\"\n",
    "TLS_COLOR = \"#F07D12\"\n",
    "MANUAL_COLOR = \"#459E11\"\n",
    "\n",
    "MIXED_MARKER = \"o\"\n",
    "DECIDUOUS_MARKER = \"x\"\n",
    "CONIFER_MARKER = \"^\"\n",
    "\n",
    "for plot_type in datasets.keys():\n",
    "    print(f\"Loading {plot_type} dataset\")\n",
    "    tree_manager_path = os.path.join(paths[plot_type], \"tree_manager.pkl\")\n",
    "    april_tag_pos_path = os.path.join(paths[plot_type], \"april_tag_locations.csv\")\n",
    "    april_tag_measurement_path = os.path.join(paths[plot_type], \"forester_data.csv\")\n",
    "    ground_cloud_path = os.path.join(paths[plot_type], \"ground_cloud.las\")\n",
    "\n",
    "    # reconstructed trees\n",
    "    ours_trees = []\n",
    "    with open(tree_manager_path, 'rb') as file:\n",
    "        tm : TreeManager = pickle.load(file)\n",
    "        ours_trees = tm.trees\n",
    "\n",
    "    # ground truth trees\n",
    "    id = 0\n",
    "    tls_trees = []\n",
    "    for file_name in os.listdir(paths[plot_type]):\n",
    "        if file_name.endswith(\".csv\") and \"_result\" in file_name:\n",
    "            with open(os.path.join(paths[plot_type], file_name), 'r') as file:\n",
    "                csv_reader = csv.DictReader(file)\n",
    "                circle_stack = []\n",
    "                for row in csv_reader:\n",
    "                    circle = Circle(\n",
    "                        np.array([\n",
    "                            float(row[\"center_x\"]),\n",
    "                            float(row[\"center_y\"]),\n",
    "                            float(row[\"slice_height\"])\n",
    "                        ]), \n",
    "                        float(row[\"radius\"]))\n",
    "                    circle_stack.append(circle)\n",
    "                \n",
    "                tree = Tree(id)\n",
    "                tree.reconstructed = True\n",
    "                tree.circles = circle_stack\n",
    "                transform = np.eye(4)\n",
    "                dir_vec = circle_stack[2].center - circle_stack[1].center\n",
    "                dir_vec /= np.linalg.norm(dir_vec)\n",
    "                dir_vec_normal = np.array([-dir_vec[1], dir_vec[0], 0])\n",
    "                dir_vec_normal /= np.linalg.norm(dir_vec_normal)\n",
    "                transform[:3, 2] = dir_vec\n",
    "                transform[:3, 0] = dir_vec_normal\n",
    "                transform[:3, 1] = np.cross(dir_vec, dir_vec_normal)\n",
    "                transform[:3, 3] = circle_stack[0].center\n",
    "                tree.clusters = [{\n",
    "                    \"info\": {\n",
    "                        \"T_sensor2map\": np.eye(4),\n",
    "                        \"axis\": {\n",
    "                            \"transform\": transform,\n",
    "                            \"radius\": circle_stack[0].radius\n",
    "                        },\n",
    "                        \"file\": file_name\n",
    "                    }\n",
    "                }]\n",
    "                tls_trees.append(tree)\n",
    "                id += 1\n",
    "\n",
    "    # april tags\n",
    "    with open(april_tag_pos_path, 'r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        april_tag_positions = {int(row[\"tag_id\"]): np.array([float(row[\"x\"]), float(row[\"y\"]), float(row[\"z\"])]) for row in csv_reader}\n",
    "\n",
    "    # manual DBHs\n",
    "    dbhs = {}\n",
    "    with open(april_tag_measurement_path, 'r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            if row[\"DBH [cm]\"] == \"\":\n",
    "                continue\n",
    "            dbhs[int(row[\"Tree\"])] = float(row[\"DBH [cm]\"].replace(\",\", \".\"))\n",
    "\n",
    "    # tree matching\n",
    "    tree_tuples = []\n",
    "    for i_gt, tls_tree in enumerate(tls_trees):\n",
    "        result = {\"tls_tree\": tls_tree,}\n",
    "        gt_axis = {\"transform\": tls_tree.axis[\"transform\"]}\n",
    "        matches = 0\n",
    "        for ours_tree in ours_trees:\n",
    "            ours_axis = {\"transform\": ours_tree.axis[\"transform\"]}\n",
    "            dist = distance_line_to_line(gt_axis, ours_axis, clip_heights=[0,10])\n",
    "            if dist < 0.5:\n",
    "                result[\"ours_tree\"] = ours_tree\n",
    "        for k, v in april_tag_positions.items():\n",
    "            if np.linalg.norm(v[:2] - tls_tree.axis[\"transform\"][:2, 3]) < 0.5:\n",
    "                result[\"april_tag\"] = k \n",
    "                result[\"manual_dbh\"] = dbhs[k]\n",
    "        if \"ours_tree\" in result:\n",
    "            tree_tuples.append(result)\n",
    "\n",
    "    print(f\"Detection Precision: {len(tree_tuples) / id * 100 :.2f} %\")\n",
    "\n",
    "    terrain_cloud = laspy.read(ground_cloud_path)\n",
    "    terrain_cloud = np.vstack((terrain_cloud.x, terrain_cloud.y, terrain_cloud.z)).T\n",
    "    terrain_cloud = o3d.t.geometry.PointCloud(terrain_cloud)\n",
    "    terrain = TerrainFitting().process(cloud=terrain_cloud)\n",
    "    terrain_interpolator = RegularGridInterpolator(\n",
    "        points=(terrain[:, 0, 0], terrain[0, :, 1]),\n",
    "        values=terrain[:, :, 2],\n",
    "        method=\"linear\",\n",
    "        bounds_error=False,\n",
    "        fill_value=None\n",
    "    )\n",
    "    datasets[plot_type][\"tuples\"] = tree_tuples\n",
    "    datasets[plot_type][\"terrain\"] = terrain_interpolator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 01: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from digiforest_analysis.utils.meshing import meshgrid_to_mesh\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from digiforest_analysis.tasks.tree_reconstruction import Tree, Circle\n",
    "\n",
    "selection = None\n",
    "if selection:\n",
    "    tree_pair_iter = tqdm(tree_tuples[selection: selection+1])\n",
    "else:\n",
    "    tree_pair_iter = tqdm(tree_tuples)\n",
    "\n",
    "manual_dbhs = []\n",
    "tls_dbhs = []\n",
    "ours_dbhs = []\n",
    "viz_objects = []\n",
    "for tree_pair in tree_pair_iter:\n",
    "    ground_elevation = terrain_interpolator(tree_pair[\"tls_tree\"].axis[\"transform\"][:2, 3])[0]\n",
    "    # manual measurement\n",
    "    manual_dbhs.append(tree_pair[\"manual_dbh\"] if \"manual_dbh\" in tree_pair else np.nan)\n",
    "    \n",
    "    # TLS measurement\n",
    "    tls_tree : Tree = tree_pair[\"tls_tree\"]\n",
    "    tls_tree.compute_dbh(ground_elevation)\n",
    "    tls_dbhs.append(tls_tree.dbh * 100 if tls_tree.dbh is not None else np.nan)\n",
    "    \n",
    "    # Ours measurement\n",
    "    ours_tree : Tree = tree_pair[\"ours_tree\"]\n",
    "    if ours_tree.reconstruct3(max_radius=0.3):\n",
    "        ours_tree.compute_dbh(ground_elevation)\n",
    "        ours_dbhs.append(ours_tree.dbh * 100 if ours_tree.dbh is not None else np.nan)\n",
    "    else:\n",
    "        ours_dbhs.append(np.nan)\n",
    "    \n",
    "    if tls_tree.dbh is not None and ours_tree.dbh is not None:\n",
    "        verts, tris = tls_tree.generate_mesh()\n",
    "        mesh = o3d.geometry.TriangleMesh(o3d.utility.Vector3dVector(verts), o3d.utility.Vector3iVector(tris))\n",
    "        mesh.paint_uniform_color([0.2, 0.8, 0.2])\n",
    "        mesh.compute_vertex_normals()\n",
    "        viz_objects.append(mesh)\n",
    "        \n",
    "        verts, tris = ours_tree.generate_mesh()\n",
    "        mesh = o3d.geometry.TriangleMesh(o3d.utility.Vector3dVector(verts), o3d.utility.Vector3iVector(tris))\n",
    "        mesh.paint_uniform_color([0.8, 0.2, 0.2])\n",
    "        mesh.compute_vertex_normals()\n",
    "        viz_objects.append(mesh)\n",
    "        \n",
    "        point_cloud = o3d.t.geometry.PointCloud(ours_tree.points)\n",
    "        point_cloud.paint_uniform_color([0, 0, 1])\n",
    "        point_cloud = point_cloud.to_legacy()\n",
    "        viz_objects.append(point_cloud)\n",
    "\n",
    "verts, tris = meshgrid_to_mesh(terrain)\n",
    "mesh = o3d.geometry.TriangleMesh(\n",
    "    o3d.utility.Vector3dVector(verts),\n",
    "    o3d.utility.Vector3iVector(tris)\n",
    ")\n",
    "mesh.compute_vertex_normals()\n",
    "viz_objects.append(mesh)\n",
    "\n",
    "if not selection:\n",
    "    data = []\n",
    "    for i in range(len(tree_tuples)):\n",
    "        tree_tuple = tree_tuples[i]\n",
    "        data_dict = {\n",
    "            \"file_name\": tree_tuple[\"tls_tree\"].clusters[0][\"info\"][\"file\"],\n",
    "            \"ours_id\": tree_tuple[\"ours_tree\"].id,\n",
    "            \"manual_dbh\": manual_dbhs[i],\n",
    "            \"tls_dbh\": tls_dbhs[i],\n",
    "            \"ours_dbh\": ours_dbhs[i]\n",
    "        }\n",
    "        if tree_tuple[\"ours_tree\"].reconstructed:\n",
    "            data_dict.update({\n",
    "                \"ours_centers_x\": [c.center[0] for c in tree_tuple[\"ours_tree\"].circles],\n",
    "                \"ours_centers_y\": [c.center[1] for c in tree_tuple[\"ours_tree\"].circles],\n",
    "                \"ours_centers_z\": [c.center[2] for c in tree_tuple[\"ours_tree\"].circles],\n",
    "                \"ours_radii\": [c.radius for c in tree_tuple[\"ours_tree\"].circles],\n",
    "            })\n",
    "        else: \n",
    "            data_dict.update({\"ours_centers_x\": [], \"ours_centers_y\": [], \"ours_centers_z\": [], \"ours_diameters\": []})\n",
    "        if tree_tuple[\"tls_tree\"].reconstructed:\n",
    "            data_dict.update({\n",
    "                \"tls_centers_x\": [c.center[0] for c in tree_tuple[\"tls_tree\"].circles],\n",
    "                \"tls_centers_y\": [c.center[1] for c in tree_tuple[\"tls_tree\"].circles],\n",
    "                \"tls_centers_z\": [c.center[2] for c in tree_tuple[\"tls_tree\"].circles], \n",
    "                \"tls_diameters\": [c.radius for c in tree_tuple[\"tls_tree\"].circles],\n",
    "            })\n",
    "        else:\n",
    "            data_dict.update({\"tls_centers_x\": [], \"tls_centers_y\": [], \"tls_centers_z\": [], \"tls_radii\": []})\n",
    "        data.append(data_dict)\n",
    "    suffixes = {\"M\": \"mixed\", \"D\": \"deciduous\", \"C\": \"conifer\"}\n",
    "    with open(f\"/home/ori/git/digiforest_drs/trees/evaluation/evaluation_{suffixes[data_path[-1]]}.csv\", \"w+\") as file:\n",
    "        csv_writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "        csv_writer.writeheader()\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "    measurements = np.stack([tls_dbhs, manual_dbhs, ours_dbhs], axis=1)\n",
    "    mask = ~np.isnan(measurements).any(axis=1)\n",
    "    msrmnt_triplets = measurements[mask]\n",
    "    sorting = np.argsort(msrmnt_triplets[:, 1])[::-1]\n",
    "    msrmnt_triplets = msrmnt_triplets[sorting]\n",
    "    sorted_and_measured_inds = np.arange(len(tree_tuples))[mask][sorting]\n",
    "    tls_dbhs = msrmnt_triplets[:, 0]\n",
    "    manual_dbhs = msrmnt_triplets[:, 1]\n",
    "    ours_dbhs = msrmnt_triplets[:, 2]\n",
    "    fig_bias_std, ax_bias_std = plt.subplots(figsize=(10, 5))\n",
    "    ax_bias_std.plot(range(len(manual_dbhs)), manual_dbhs, label=\"manual\", marker='o', color=MANUAL_COLOR)\n",
    "    ax_bias_std.plot(range(len(tls_dbhs)), tls_dbhs, label=\"TLS\", marker='o', color=TLS_COLOR)\n",
    "    ax_bias_std.plot(range(len(ours_dbhs)), ours_dbhs, label=\"Ours\", marker='o', color=OURS_COLOR)\n",
    "    ax_bias_std.set_xticks(range(len(sorted_and_measured_inds)), sorted_and_measured_inds)\n",
    "    ax_bias_std.legend()\n",
    "else:\n",
    "    print(tree_tuples[selection][\"ours_tree\"].reconstructed)\n",
    "    print(tree_tuples[selection][\"tls_tree\"].dbh, tree_tuples[selection][\"ours_tree\"].dbh) \n",
    "    o3d.visualization.draw_geometries(viz_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_nan(arr):\n",
    "    return arr[~np.isnan(arr)]\n",
    "\n",
    "# Load Reconstruction Results\n",
    "results = {}\n",
    "evaluations = {}\n",
    "\n",
    "for plot_type in [\"mixed\", \"deciduous\", \"conifer\", \"all\"]:\n",
    "    results[plot_type] = []\n",
    "    evaluations[plot_type] = []\n",
    "    for i in range(3):\n",
    "        if plot_type != \"all\":\n",
    "            sub_result = {\n",
    "                \"file_names\": [],\n",
    "                \"ours_ids\": [],\n",
    "                \"manual_dbhs\": [],\n",
    "                \"tls_trees\": [],\n",
    "                \"ours_trees\": []\n",
    "            }\n",
    "            sub_evaluation = {}\n",
    "            # load csv\n",
    "            with open(f\"/home/ori/git/digiforest_drs/trees/evaluation/evaluation_{plot_type}_{i}.csv\", \"r\") as file:\n",
    "                csv_reader = csv.DictReader(file)\n",
    "                for row in csv_reader:\n",
    "                    sub_result[\"file_names\"].append(row[\"file_name\"])\n",
    "                    sub_result[\"ours_ids\"].append(int(row[\"ours_id\"]))\n",
    "                    sub_result[\"manual_dbhs\"].append(float(row[\"manual_dbh\"]))\n",
    "                    \n",
    "                    tls_tree = Tree(int(row[\"file_name\"].split(\"_\")[1]))\n",
    "                    tls_centers_x = [float(x) for x in row[\"tls_centers_x\"].strip(\"[]\").split(\", \") if x != \"\"]\n",
    "                    tls_centers_y = [float(y) for y in row[\"tls_centers_y\"].strip(\"[]\").split(\", \") if y != \"\"]\n",
    "                    tls_centers_z = [float(z) for z in row[\"tls_centers_z\"].strip(\"[]\").split(\", \") if z != \"\"]\n",
    "                    tls_radii = [float(r) for r in row[\"tls_radii\"].strip(\"[]\").split(\", \") if r != \"\"]\n",
    "                    tls_tree.circles = [Circle(np.array([x, y, z]), r) for x, y, z, r in zip(tls_centers_x, tls_centers_y, tls_centers_z, tls_radii)]\n",
    "                    tls_dbh = float(row[\"tls_dbh\"])\n",
    "                    if not np.isnan(tls_dbh):\n",
    "                        tls_tree.dbh = tls_dbh\n",
    "                        tls_tree.reconstructed = True\n",
    "                    sub_result[\"tls_trees\"].append(tls_tree)\n",
    "                    \n",
    "                    ours_tree = Tree(int(row[\"ours_id\"]))\n",
    "                    ours_centers_x = [float(x) for x in row[\"ours_centers_x\"].strip(\"[]\").split(\", \") if x != \"\"]\n",
    "                    ours_centers_y = [float(y) for y in row[\"ours_centers_y\"].strip(\"[]\").split(\", \") if y != \"\"]\n",
    "                    ours_centers_z = [float(z) for z in row[\"ours_centers_z\"].strip(\"[]\").split(\", \") if z != \"\"]\n",
    "                    ours_radii = [float(r) for r in row[\"ours_radii\"].strip(\"[]\").split(\", \") if r != \"\"]\n",
    "                    ours_tree.circles = [Circle(np.array([x, y, z]), r) for x, y, z, r in zip(ours_centers_x, ours_centers_y, ours_centers_z, ours_radii)]\n",
    "                    ours_dbh = float(row[\"ours_dbh\"])\n",
    "                    if not np.isnan(ours_dbh):\n",
    "                        ours_tree.dbh = ours_dbh\n",
    "                        ours_tree.reconstructed = True\n",
    "                    sub_result[\"ours_trees\"].append(ours_tree)\n",
    "            \n",
    "            # apply global shift to fine-align ours_trees with tls_trees\n",
    "            errors = []\n",
    "            for tls_tree, ours_tree in zip(sub_result[\"tls_trees\"], sub_result[\"ours_trees\"]):\n",
    "                if ours_tree.reconstructed:\n",
    "                    tree_errors = []\n",
    "                    for c_ours in ours_tree.circles:\n",
    "                        c_tls = tls_tree.evaluate_at_height(c_ours.center[2])\n",
    "                        if c_tls:\n",
    "                            tree_errors.append(c_ours.center - c_tls.center)\n",
    "                    errors.append(np.array(tree_errors))  \n",
    "            mean_errors = np.mean(np.vstack(errors), axis=0)\n",
    "            for ours_tree in sub_result[\"ours_trees\"]:\n",
    "                for circle in ours_tree.circles:\n",
    "                    circle.center -= mean_errors\n",
    "        elif plot_type == \"all\":\n",
    "            sub_result = {\n",
    "                \"file_names\": results[\"mixed\"][i][\"file_names\"] + results[\"deciduous\"][i][\"file_names\"] + results[\"conifer\"][i][\"file_names\"],\n",
    "                \"ours_ids\": results[\"mixed\"][i][\"ours_ids\"] + results[\"deciduous\"][i][\"ours_ids\"] + results[\"conifer\"][i][\"ours_ids\"],\n",
    "                \"manual_dbhs\": results[\"mixed\"][i][\"manual_dbhs\"] + results[\"deciduous\"][i][\"manual_dbhs\"] + results[\"conifer\"][i][\"manual_dbhs\"],\n",
    "                \"tls_trees\": results[\"mixed\"][i][\"tls_trees\"] + results[\"deciduous\"][i][\"tls_trees\"] + results[\"conifer\"][i][\"tls_trees\"],\n",
    "                \"ours_trees\": results[\"mixed\"][i][\"ours_trees\"] + results[\"deciduous\"][i][\"ours_trees\"] + results[\"conifer\"][i][\"ours_trees\"]\n",
    "            }\n",
    "        # evaluate\n",
    "        if plot_type != \"all\":\n",
    "            ours_dbhs = np.array([tree.dbh  if tree.dbh else np.nan for tree in sub_result[\"ours_trees\"]])\n",
    "            tls_dbhs = np.array([tree.dbh  if tree.dbh else np.nan for tree in sub_result[\"tls_trees\"]])\n",
    "            manual_dbhs = np.array(sub_result[\"manual_dbhs\"])\n",
    "            sub_evaluation[\"dbh\"] = {\n",
    "                \"diffs\": {\n",
    "                    \"ours2tls\": (tls_dbhs - ours_dbhs),\n",
    "                    \"tls2manual\": (manual_dbhs - tls_dbhs),\n",
    "                    \"ours2manual\": (manual_dbhs - ours_dbhs),\n",
    "                },\n",
    "                \"ours\" : ours_dbhs,\n",
    "                \"tls\": tls_dbhs,\n",
    "                \"manual\": manual_dbhs\n",
    "            }\n",
    "            ours_centers = []; ours_diameters = []; tls_centers = []; tls_diameters = []\n",
    "            for tls_tree, ours_tree in zip(sub_result[\"tls_trees\"], sub_result[\"ours_trees\"]):\n",
    "                oc = []; od = []; tc = []; td = []\n",
    "                if ours_tree.reconstructed:\n",
    "                    for c_ours in ours_tree.circles:\n",
    "                        c_tls = tls_tree.evaluate_at_height(c_ours.center[2])\n",
    "                        if c_tls:\n",
    "                            tc.append(c_tls.center)\n",
    "                            td.append(2 * c_tls.radius)\n",
    "                            oc.append(c_ours.center)\n",
    "                            od.append(2 * c_ours.radius)\n",
    "                ours_centers.append(np.array(oc)); ours_diameters.append(np.array(od)); tls_centers.append(np.array(tc)); tls_diameters.append(np.array(td))\n",
    "            sub_evaluation[\"stem\"] = {\n",
    "                \"ours_centers\" : ours_centers,\n",
    "                \"ours_diameters\" : ours_diameters,\n",
    "                \"tls_centers\" : tls_centers,\n",
    "                \"tls_diameters\" : tls_diameters\n",
    "            }\n",
    "            sub_evaluation[\"height\"] = {\n",
    "                \"ours_heights\" : np.array([tree.circles[-1].center[2] - tree.circles[0].center[2]  if tree.reconstructed else np.nan for tree in sub_result[\"ours_trees\"]]),\n",
    "                \"tls_heights\" : np.array([tree.circles[-1].center[2] - tree.circles[0].center[2] for tree in sub_result[\"tls_trees\"]])\n",
    "            }\n",
    "            \n",
    "        elif plot_type == \"all\":\n",
    "            sub_evaluation[\"dbh\"] = {\n",
    "                \"diffs\": {\n",
    "                    \"ours2tls\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"diffs\"][\"ours2tls\"], evaluations[\"deciduous\"][i][\"dbh\"][\"diffs\"][\"ours2tls\"], evaluations[\"conifer\"][i][\"dbh\"][\"diffs\"][\"ours2tls\"]]),\n",
    "                    \"tls2manual\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"diffs\"][\"tls2manual\"], evaluations[\"deciduous\"][i][\"dbh\"][\"diffs\"][\"tls2manual\"], evaluations[\"conifer\"][i][\"dbh\"][\"diffs\"][\"tls2manual\"]]),\n",
    "                    \"ours2manual\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"diffs\"][\"ours2manual\"], evaluations[\"deciduous\"][i][\"dbh\"][\"diffs\"][\"ours2manual\"], evaluations[\"conifer\"][i][\"dbh\"][\"diffs\"][\"ours2manual\"]]),\n",
    "                },\n",
    "                \"ours\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"ours\"], evaluations[\"deciduous\"][i][\"dbh\"][\"ours\"], evaluations[\"conifer\"][i][\"dbh\"][\"ours\"]]),\n",
    "                \"tls\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"tls\"], evaluations[\"deciduous\"][i][\"dbh\"][\"tls\"], evaluations[\"conifer\"][i][\"dbh\"][\"tls\"]]),\n",
    "                \"manual\" : np.hstack([evaluations[\"mixed\"][i][\"dbh\"][\"manual\"], evaluations[\"deciduous\"][i][\"dbh\"][\"manual\"], evaluations[\"conifer\"][i][\"dbh\"][\"manual\"]])\n",
    "            }\n",
    "            sub_evaluation[\"stem\"] = {\n",
    "                \"ours_centers\" : evaluations[\"mixed\"][i][\"stem\"][\"ours_centers\"] + evaluations[\"deciduous\"][i][\"stem\"][\"ours_centers\"] + evaluations[\"conifer\"][i][\"stem\"][\"ours_centers\"],\n",
    "                \"ours_diameters\" : evaluations[\"mixed\"][i][\"stem\"][\"ours_diameters\"] + evaluations[\"deciduous\"][i][\"stem\"][\"ours_diameters\"] + evaluations[\"conifer\"][i][\"stem\"][\"ours_diameters\"],\n",
    "                \"tls_centers\" : evaluations[\"mixed\"][i][\"stem\"][\"tls_centers\"] + evaluations[\"deciduous\"][i][\"stem\"][\"tls_centers\"] + evaluations[\"conifer\"][i][\"stem\"][\"tls_centers\"],\n",
    "                \"tls_diameters\" : evaluations[\"mixed\"][i][\"stem\"][\"tls_diameters\"] + evaluations[\"deciduous\"][i][\"stem\"][\"tls_diameters\"] + evaluations[\"conifer\"][i][\"stem\"][\"tls_diameters\"]\n",
    "            }\n",
    "            sub_evaluation[\"height\"] = {\n",
    "                \"ours_heights\" : np.hstack([evaluations[\"mixed\"][i][\"height\"][\"ours_heights\"], evaluations[\"deciduous\"][i][\"height\"][\"ours_heights\"], evaluations[\"conifer\"][i][\"height\"][\"ours_heights\"]]),\n",
    "                \"tls_heights\" : np.hstack([evaluations[\"mixed\"][i][\"height\"][\"tls_heights\"], evaluations[\"deciduous\"][i][\"height\"][\"tls_heights\"], evaluations[\"conifer\"][i][\"height\"][\"tls_heights\"]])\n",
    "            }\n",
    "        \n",
    "        # aggregate metrics\n",
    "        sub_evaluation[\"dbh\"][\"metrics\"] = {\n",
    "            \"RMSE_ours2tls\": np.sqrt(np.mean(np.square(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2tls\"])))),\n",
    "            \"RMSE_ours2manual\": np.sqrt(np.mean(np.square(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2manual\"])))),\n",
    "            \"RMSE_tls2manual\": np.sqrt(np.mean(np.square(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"tls2manual\"])))),\n",
    "            \"bias_ours2tls\": np.mean(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2tls\"])),\n",
    "            \"bias_ours2manual\": np.mean(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2manual\"])),\n",
    "            \"bias_tls2manual\": np.mean(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"tls2manual\"])),\n",
    "            \"std_ours2tls\": np.std(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2tls\"])),\n",
    "            \"std_ours2manual\": np.std(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2manual\"])),\n",
    "            \"std_tls2manual\": np.std(non_nan(sub_evaluation[\"dbh\"][\"diffs\"][\"tls2manual\"])),\n",
    "            \"MAPE_ours2manual\": np.mean(non_nan(np.abs(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2manual\"]) / sub_evaluation[\"dbh\"][\"manual\"])) * 100,\n",
    "            \"MAPE_tls2manual\": np.mean(non_nan(np.abs(sub_evaluation[\"dbh\"][\"diffs\"][\"tls2manual\"]) / sub_evaluation[\"dbh\"][\"manual\"])) * 100,\n",
    "            \"MAPE_ours2tls\": np.mean(non_nan(np.abs(sub_evaluation[\"dbh\"][\"diffs\"][\"ours2tls\"]) / sub_evaluation[\"dbh\"][\"tls\"])) * 100,\n",
    "        }\n",
    "        sub_evaluation[\"stem\"][\"metrics\"] = {\n",
    "            \"RMSE_centers\": 100 * np.sqrt(np.mean(np.square(np.hstack([np.linalg.norm(ours - tls, axis=1) for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_centers\"], sub_evaluation[\"stem\"][\"tls_centers\"]) if (ours - tls).shape[0] > 0])))),\n",
    "            \"RMSE_diameters\": 100 * np.sqrt(np.mean(np.square(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])))),\n",
    "            \"bias_centers\": 100 * np.mean(np.hstack([np.linalg.norm(ours - tls, axis=1) for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_centers\"], sub_evaluation[\"stem\"][\"tls_centers\"]) if (ours - tls).shape[0] > 0])),\n",
    "            \"bias_diameters\": 100 * np.mean(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])),\n",
    "            \"std_centers\": 100 * np.std(np.hstack([np.linalg.norm(ours - tls, axis=1) for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_centers\"], sub_evaluation[\"stem\"][\"tls_centers\"]) if (ours - tls).shape[0] > 0])),\n",
    "            \"std_diameters\": 100 * np.std(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])),\n",
    "            \"MAPE_diameters\": np.mean(np.abs(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])) / np.hstack([tls for tls in sub_evaluation[\"stem\"][\"tls_diameters\"]])) * 100,\n",
    "            \"RMSE_rel_diameters\": np.sqrt(np.mean(np.square(np.hstack([ours - tls for ours, tls in zip(sub_evaluation[\"stem\"][\"ours_diameters\"], sub_evaluation[\"stem\"][\"tls_diameters\"])])) / np.hstack(tls for tls in sub_evaluation[\"stem\"][\"tls_diameters\"]))) * 100,\n",
    "        }\n",
    "        sub_evaluation[\"height\"][\"metrics\"] = {\n",
    "            \"mean_ours\": np.mean(non_nan(sub_evaluation[\"height\"][\"ours_heights\"])),\n",
    "            \"mean_tls\": np.mean(non_nan(sub_evaluation[\"height\"][\"tls_heights\"])),\n",
    "        }\n",
    "        \n",
    "        results[plot_type].append(sub_result)\n",
    "        evaluations[plot_type].append(sub_evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\n",
    "    \"dbh/RMSE_ours2manual\",\n",
    "    \"dbh/RMSE_ours2tls\",\n",
    "    \"dbh/RMSE_tls2manual\",\n",
    "    \"\",\n",
    "    \"dbh/RMSE_ours2manual\",\n",
    "    \"dbh/bias_ours2manual\",\n",
    "    \"dbh/std_ours2manual\",\n",
    "    \"\",\n",
    "    \"dbh/bias_ours2tls\",\n",
    "    \"dbh/bias_ours2manual\",\n",
    "    \"dbh/bias_tls2manual\",\n",
    "    \"\",\n",
    "    \"dbh/MAPE_ours2manual\",\n",
    "    \"dbh/MAPE_tls2manual\",\n",
    "    \"dbh/MAPE_ours2tls\",\n",
    "    \"-\",\n",
    "    \"stem/RMSE_centers\",\n",
    "    \"stem/bias_centers\",\n",
    "    \"stem/std_centers\",\n",
    "    \"\",\n",
    "    \"stem/RMSE_diameters\",\n",
    "    \"stem/bias_diameters\",\n",
    "    \"stem/std_diameters\",\n",
    "    \"-\",\n",
    "    \"height/mean_ours\",\n",
    "    \"height/mean_tls\",\n",
    "]\n",
    "\n",
    "print(f\"\\033[1mmetric_name         |     conifer       mixed   deciduous |        all\\033[0m\")\n",
    "print(f\"----------------------------------------------------------------------\")\n",
    "for metric_name in metric_names:\n",
    "    if metric_name == \"\":\n",
    "        print()\n",
    "        continue\n",
    "    if metric_name == \"-\":\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        continue\n",
    "    metric_first, metric_second = metric_name.split(\"/\")\n",
    "    mean_metric_conifer = np.mean([e[metric_first][\"metrics\"][metric_second] for e in evaluations[\"conifer\"]])\n",
    "    mean_metric_mixed = np.mean([e[metric_first][\"metrics\"][metric_second] for e in evaluations[\"mixed\"]])\n",
    "    mean_metric_deciduous = np.mean([e[metric_first][\"metrics\"][metric_second] for e in evaluations[\"deciduous\"]])\n",
    "    mean_metric_all = np.mean([e[metric_first][\"metrics\"][metric_second] for e in evaluations[\"all\"]])\n",
    "    print(f\"{metric_name:<20}|{mean_metric_conifer:>12.2f}{mean_metric_mixed:>12.2f}{mean_metric_deciduous:>12.2f} | {mean_metric_all:>10.2f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 8.36        6.30        3.30 |       6.12\n",
    "17.16       15.22        5.94 |      10.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)\n",
    "# tls manual ours\n",
    "\n",
    "plot_config = {\n",
    "    \"mixed\": {\n",
    "        \"marker\": MIXED_MARKER,\n",
    "        \"marker_size\": 20,\n",
    "        \"title\": \"Mixed Plot\",\n",
    "    },\n",
    "    \"deciduous\": {\n",
    "        \"marker\": DECIDUOUS_MARKER,\n",
    "        \"marker_size\": 30,\n",
    "        \"title\":\"Deciduous Trees\",\n",
    "        },\n",
    "    \"conifer\": {\n",
    "        \"marker\": CONIFER_MARKER,\n",
    "        \"marker_size\": 15,\n",
    "        \"title\": \"Conifer Trees\",\n",
    "    },\n",
    "    \"all\": {\n",
    "        \"title\":\"All Trees\",\n",
    "    }\n",
    "}\n",
    "\n",
    "non_nan_row = lambda arr: arr[~np.isnan(arr).any(axis=1)]\n",
    "data_points = {\n",
    "    \"mixed\" : {\n",
    "        \"ours2tls\": non_nan_row(np.vstack([evaluations[\"mixed\"][i][\"dbh\"][\"ours\"], evaluations[\"mixed\"][i][\"dbh\"][\"tls\"]]).T),\n",
    "        \"ours2manual\": non_nan_row(np.vstack([evaluations[\"mixed\"][i][\"dbh\"][\"ours\"], evaluations[\"mixed\"][i][\"dbh\"][\"manual\"]]).T)\n",
    "    },\n",
    "    \"deciduous\" : {\n",
    "        \"ours2tls\": non_nan_row(np.vstack([evaluations[\"deciduous\"][i][\"dbh\"][\"ours\"], evaluations[\"deciduous\"][i][\"dbh\"][\"tls\"]]).T),\n",
    "        \"ours2manual\": non_nan_row(np.vstack([evaluations[\"deciduous\"][i][\"dbh\"][\"ours\"], evaluations[\"deciduous\"][i][\"dbh\"][\"manual\"]]).T)\n",
    "    },\n",
    "    \"conifer\" : {\n",
    "        \"ours2tls\": non_nan_row(np.vstack([evaluations[\"conifer\"][i][\"dbh\"][\"ours\"], evaluations[\"conifer\"][i][\"dbh\"][\"tls\"]]).T),\n",
    "        \"ours2manual\": non_nan_row(np.vstack([evaluations[\"conifer\"][i][\"dbh\"][\"ours\"], evaluations[\"conifer\"][i][\"dbh\"][\"manual\"]]).T)\n",
    "    }\n",
    "}\n",
    "data_points[\"mixed\"][\"min_radius\"] = data_points[\"mixed\"][\"ours2tls\"].min()\n",
    "data_points[\"mixed\"][\"max_radius\"] = data_points[\"mixed\"][\"ours2tls\"].max()\n",
    "data_points[\"deciduous\"][\"min_radius\"] = data_points[\"deciduous\"][\"ours2tls\"].min()\n",
    "data_points[\"deciduous\"][\"max_radius\"] = data_points[\"deciduous\"][\"ours2tls\"].max()\n",
    "data_points[\"conifer\"][\"min_radius\"] = data_points[\"conifer\"][\"ours2tls\"].min()\n",
    "data_points[\"conifer\"][\"max_radius\"] = data_points[\"conifer\"][\"ours2tls\"].max()\n",
    "data_points[\"all\"] = {\n",
    "    \"min_radius\": np.min([data_points[\"mixed\"][\"min_radius\"], data_points[\"deciduous\"][\"min_radius\"], data_points[\"conifer\"][\"min_radius\"]]),\n",
    "    \"max_radius\": np.max([data_points[\"mixed\"][\"max_radius\"], data_points[\"deciduous\"][\"max_radius\"], data_points[\"conifer\"][\"max_radius\"]]),\n",
    "}\n",
    "\n",
    "index = 2\n",
    "for plot_type in [\"mixed\", \"deciduous\", \"conifer\", \"all\"]:\n",
    "    fig_bias_std, ax_bias_std = plt.subplots(1, 1, figsize=(3.3, 3.3))\n",
    "    fig_bias_std.tight_layout()\n",
    "    min_radius = data_points[plot_type][\"min_radius\"]\n",
    "    max_radius = data_points[plot_type][\"max_radius\"]\n",
    "    ax_bias_std.plot([min_radius, max_radius], [min_radius, max_radius], color=\"#6E6E6E\", linestyle='dashed', zorder=0)\n",
    "    if plot_type == \"all\":\n",
    "        ax_bias_std.scatter(data_points[\"conifer\"][\"ours2tls\"][:, 0], data_points[\"conifer\"][\"ours2tls\"][:, 1], marker=plot_config[\"conifer\"][\"marker\"], s=plot_config[\"conifer\"][\"marker_size\"], color=TLS_COLOR, zorder=1)\n",
    "        ax_bias_std.scatter(data_points[\"conifer\"][\"ours2manual\"][:, 0], data_points[\"conifer\"][\"ours2manual\"][:, 1], marker=plot_config[\"conifer\"][\"marker\"], s=plot_config[\"conifer\"][\"marker_size\"], color=MANUAL_COLOR, zorder=1)\n",
    "        ax_bias_std.scatter(data_points[\"mixed\"][\"ours2tls\"][:, 0], data_points[\"mixed\"][\"ours2tls\"][:, 1], marker=plot_config[\"mixed\"][\"marker\"], s=plot_config[\"mixed\"][\"marker_size\"], color=TLS_COLOR, zorder=1)\n",
    "        ax_bias_std.scatter(data_points[\"mixed\"][\"ours2manual\"][:, 0], data_points[\"mixed\"][\"ours2manual\"][:, 1], marker=plot_config[\"mixed\"][\"marker\"], s=plot_config[\"mixed\"][\"marker_size\"], color=MANUAL_COLOR, zorder=1)\n",
    "        ax_bias_std.scatter(data_points[\"deciduous\"][\"ours2tls\"][:, 0], data_points[\"deciduous\"][\"ours2tls\"][:, 1], marker=plot_config[\"deciduous\"][\"marker\"], s=plot_config[\"deciduous\"][\"marker_size\"], color=TLS_COLOR, zorder=1)\n",
    "        ax_bias_std.scatter(data_points[\"deciduous\"][\"ours2manual\"][:, 0], data_points[\"deciduous\"][\"ours2manual\"][:, 1], marker=plot_config[\"deciduous\"][\"marker\"], s=plot_config[\"deciduous\"][\"marker_size\"], color=MANUAL_COLOR, zorder=1)\n",
    "        legend_elements = [\n",
    "            matplotlib.lines.Line2D([0], [0], marker=MIXED_MARKER, color='w', markerfacecolor='k', markersize=10, label='Mixed'),\n",
    "            matplotlib.lines.Line2D([0], [0], marker=DECIDUOUS_MARKER, color='k', markerfacecolor='k', linestyle='', markersize=7, label='Deciduous'),\n",
    "            matplotlib.lines.Line2D([0], [0], marker=CONIFER_MARKER, color='w', markerfacecolor='k', markersize=10, label='Conifer'),\n",
    "            matplotlib.patches.Patch(color=TLS_COLOR, label='wrt. TLS'),\n",
    "            matplotlib.patches.Patch(color=MANUAL_COLOR, label='wrt. Manual'),\n",
    "        ]\n",
    "        ax_bias_std.legend(handles=legend_elements, loc='upper left')\n",
    "    else:\n",
    "        ax_bias_std.scatter(data_points[plot_type][\"ours2tls\"][:, 0], data_points[plot_type][\"ours2tls\"][:, 1], marker=plot_config[plot_type][\"marker\"], s=plot_config[plot_type][\"marker_size\"], color=TLS_COLOR, zorder=1)\n",
    "        ax_bias_std.scatter(data_points[plot_type][\"ours2manual\"][:, 0], data_points[plot_type][\"ours2manual\"][:, 1], marker=plot_config[plot_type][\"marker\"], s=plot_config[plot_type][\"marker_size\"], color=MANUAL_COLOR, zorder=1)\n",
    "    # ax.set_xlabel(\"Our DBH [cm]\")\n",
    "    # ax.set_ylabel(\"Reference DBH [cm]\")\n",
    "    ax_bias_std.set_title(plot_config[plot_type][\"title\"])\n",
    "    fig_bias_std.savefig(f\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/dbh_scatter_{plot_type}.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(viz_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "\n",
    "@widgets.interact(idx=widgets.IntSlider(min=0, max=len(centers_ours)-1, step=1, value=0))\n",
    "def update_slice_height(idx):\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(15, 8))\n",
    "    print(f\"Corr X: {correlation_x[idx]:.3f}, Corr Y: {correlation_y[idx]:.3f}, Corr Radius: {correlation_radius[idx]:.3f}\")\n",
    "    print(f\"Mean Error Dist: {mean_errors_dist[idx]*100:.3f} cm, Mean Error Radius: {mean_errors_radius[idx]*100:.3f} cm\")\n",
    "    ax[0].plot(range(len(centers_ours[idx])), [c[0] for c in centers_ours[idx]], label=\"Ours\", marker='o', color='r')\n",
    "    ax[0].plot(range(len(centers_gt[idx])), [c[0] for c in centers_gt[idx]], label=\"GT\", marker='o', color='g')\n",
    "    ax[0].set_title(\"X\")\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(range(len(centers_ours[idx])), [c[1] for c in centers_ours[idx]], label=\"Ours\", marker='o', color='r')\n",
    "    ax[1].plot(range(len(centers_gt[idx])), [c[1] for c in centers_gt[idx]], label=\"GT\", marker='o', color='g')\n",
    "    ax[1].set_title(\"Y\")\n",
    "    ax[1].legend()\n",
    "    ax[2].plot(range(len(radii_ours[idx])), radii_ours[idx], label=\"Ours\", marker='o', color='r')\n",
    "    ax[2].plot(range(len(radii_gt[idx])), radii_gt[idx], label=\"GT\", marker='o', color='g')\n",
    "    ax[2].set_title(\"Radius\")\n",
    "    ax[2].legend()\n",
    "    # fig.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(viz_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 02: Global Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 03: Ablations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "coverage_ablation_results = []\n",
    "\n",
    "for dataset in datasets.values():\n",
    "    tree_tuples = dataset[\"tuples\"]\n",
    "    terrain_interpolator = dataset[\"terrain\"]\n",
    "    for tree_tuple in tqdm(tree_tuples):\n",
    "        ground_elevation = terrain_interpolator(ours_tree.axis[\"transform\"][:2, 3])[0]\n",
    "        tree_tuple[\"tls_tree\"].compute_dbh(ground_elevation)\n",
    "        sub_result = {\"tls_dbh\" : tree_tuple[\"tls_tree\"].dbh * 100 if tree_tuple[\"tls_tree\"].dbh is not None else np.nan, \"manual_dbh\" : tree_tuple[\"manual_dbh\"] if \"manual_dbh\" in tree_tuple else np.nan, \"ours_dbh\": []}\n",
    "        ours_tree : Tree = tree_tuple[\"ours_tree\"]\n",
    "        ours_tree_clusters = ours_tree.clusters\n",
    "        cluster_coverage_angles = np.array([(c[\"info\"][\"coverage\"][\"angle_from\"], c[\"info\"][\"coverage\"][\"angle_to\"]) for c in ours_tree_clusters])\n",
    "        sort_indices = np.argsort([angle_to - angle_from for angle_from, angle_to in cluster_coverage_angles])\n",
    "        for i_sort in range(1, len(sort_indices)):\n",
    "            ours_tree.clusters = [ours_tree_clusters[i_cluster] for i_cluster in sort_indices[:i_sort]]\n",
    "            coverage_angle = tm.compute_angle_coverage(cluster_coverage_angles[sort_indices[:i_sort]])\n",
    "            ours_tree.dbh = None\n",
    "            reco_success = ours_tree.reconstruct3()\n",
    "            ours_tree.compute_dbh(ground_elevation)\n",
    "            if reco_success and ours_tree.dbh is not None:\n",
    "                reference = tree_tuple[\"manual_dbh\"] if \"manual_dbh\" in tree_tuple else tree_tuple[\"tls_tree\"].dbh * 100 if tree_tuple[\"tls_tree\"].dbh is not None else np.nan\n",
    "                if not np.isnan(reference) and abs(ours_tree.dbh * 100 - reference) > 10:\n",
    "                    sub_result[\"ours_dbh\"].append({\"coverage_angle\" : coverage_angle, \"dbh\" : np.nan})\n",
    "                else:\n",
    "                    sub_result[\"ours_dbh\"].append({\"coverage_angle\" : coverage_angle, \"dbh\" : ours_tree.dbh * 100})\n",
    "            else:\n",
    "                sub_result[\"ours_dbh\"].append({\"coverage_angle\" : coverage_angle, \"dbh\" : np.nan})\n",
    "                \n",
    "        ours_tree.clusters = ours_tree_clusters\n",
    "        coverage_ablation_results.append(sub_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)\n",
    "\n",
    "# 300 rep\n",
    "\n",
    "def smoothify(x, *y):\n",
    "    xnew = np.linspace(x.min(), x.max(), 1000)\n",
    "    y_new = []\n",
    "    for y_i in y:\n",
    "        spl = make_interp_spline(x, y_i, k=3)\n",
    "        y_new.append(spl(xnew))\n",
    "    return xnew, *y_new\n",
    "    \n",
    "\n",
    "coverage_angles = []\n",
    "errors_tls = []\n",
    "errors_manual = []\n",
    "for result in coverage_ablation_results:\n",
    "    coverage_angles.extend([np.rad2deg(r[\"coverage_angle\"]) for r in result[\"ours_dbh\"]])\n",
    "    errors_tls.extend([r[\"dbh\"] - result[\"tls_dbh\"] for r in result[\"ours_dbh\"]])\n",
    "    errors_manual.extend([r[\"dbh\"] - result[\"manual_dbh\"] for r in result[\"ours_dbh\"]])\n",
    "coverage_angles = np.array(coverage_angles)\n",
    "errors_tls = np.array(errors_tls)\n",
    "mask_tls = ~np.isnan(np.vstack([coverage_angles, errors_tls])).any(axis=0)\n",
    "errors_tls = errors_tls[mask_tls]\n",
    "coverage_angles_tls = coverage_angles[mask_tls]\n",
    "errors_manual = np.array(errors_manual)\n",
    "mask_manual = ~np.isnan(np.vstack([coverage_angles, errors_manual])).any(axis=0)    \n",
    "errors_manual = errors_manual[mask_manual]\n",
    "coverage_angles_manual = coverage_angles[mask_manual]\n",
    "\n",
    "\n",
    "means_tls = []; stds_tls = []; means_manual = []; stds_manual = []; rmses_tls = []; rmses_manual = []\n",
    "num_buckets = 15\n",
    "bucket_boundaries = np.linspace(0, 360, num_buckets + 1, endpoint=True)\n",
    "bucket_centers = (bucket_boundaries[1:] + bucket_boundaries[:-1]) / 2\n",
    "bucket_mask_tls = np.zeros(len(bucket_centers), dtype=bool)\n",
    "bucket_mask_manual = np.zeros(len(bucket_centers), dtype=bool)\n",
    "for i in range(len(bucket_boundaries) - 1):\n",
    "    # tls\n",
    "    mask_tls = np.logical_and(coverage_angles_tls > bucket_boundaries[i], coverage_angles_tls <= bucket_boundaries[i + 1])\n",
    "    if mask_tls.sum() > 3:\n",
    "        bucket_tls = errors_tls[mask_tls]\n",
    "        means_tls.append(np.mean(bucket_tls))\n",
    "        rmses_tls.append(np.sqrt(np.mean(bucket_tls ** 2)))\n",
    "        stds_tls.append(np.std(bucket_tls))\n",
    "        bucket_mask_tls[i] = True\n",
    "    \n",
    "    # manual\n",
    "    mask_manual = np.logical_and(coverage_angles_manual > bucket_boundaries[i], coverage_angles_manual <= bucket_boundaries[i + 1])\n",
    "    if mask_manual.sum() > 3:\n",
    "        bucket_manual = errors_manual[mask_manual]\n",
    "        means_manual.append(np.mean(bucket_manual))\n",
    "        rmses_manual.append(np.sqrt(np.mean(bucket_manual ** 2)))\n",
    "        stds_manual.append(np.std(bucket_manual))\n",
    "        bucket_mask_manual[i] = True\n",
    "        \n",
    "bucket_centers_tls = bucket_centers[bucket_mask_tls]\n",
    "bucket_centers_manual = bucket_centers[bucket_mask_manual]\n",
    "means_tls = np.array(means_tls); stds_tls = np.array(stds_tls); means_manual = np.array(means_manual); stds_manual = np.array(stds_manual); rmses_tls = np.array(rmses_tls); rmses_manual = np.array(rmses_manual)\n",
    "\n",
    "\n",
    "fig_rmse, ax_rmse = plt.subplots(1, 1, figsize=(7, 3))\n",
    "# tls\n",
    "ax_rmse.scatter(bucket_centers_tls, rmses_tls, label=\"TLS\", marker=\"s\", s=20, color=TLS_COLOR)\n",
    "c = np.linalg.lstsq(np.vstack([bucket_centers_tls, np.ones(len(bucket_centers_tls))]).T, rmses_tls, rcond=None)[0] # fit lsq line to rmses\n",
    "ax_rmse.plot([0, 360], [c[1], c[0] * 360 + c[1]], color=TLS_COLOR, linestyle='dashed')\n",
    "# ax_rmse.scatter(coverage_angles_tls, errors_tls, color=TLS_COLOR, s=1)\n",
    "# manual\n",
    "ax_rmse.scatter(bucket_centers_manual, rmses_manual, label=\"Manual\", marker=\"s\", s=20, color=MANUAL_COLOR)\n",
    "c = np.linalg.lstsq(np.vstack([bucket_centers_manual, np.ones(len(bucket_centers_manual))]).T, rmses_manual, rcond=None)[0] # fit lsq line to rmses\n",
    "ax_rmse.plot([0, 360], [c[1], c[0] * 360 + c[1]], color=MANUAL_COLOR, linestyle='dashed')\n",
    "# ax_rmse.scatter(coverage_angles_manual, errors_manual, color=MANUAL_COLOR, s=1)\n",
    "ax_rmse.set_xlabel(\"Coverage Angle [deg]\")\n",
    "ax_rmse.set_ylabel(\"RMSE [cm]\")\n",
    "ax_rmse.legend()\n",
    "fig_rmse.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/coverage_ablation_rmse.pdf\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "fig_bias_std, ax_bias_std = plt.subplots(1, 1, figsize=(7, 3))\n",
    "ax_bias_std.plot([0, 360], [0, 0], color=\"#6E6E6E\", linestyle='dashed', zorder=0)\n",
    "# tls\n",
    "# bucket_centers_tls, means_tls, stds_tls = smoothify(bucket_centers_tls, means_tls, stds_tls)\n",
    "ax_bias_std.plot(bucket_centers_tls, means_tls, label=\"TLS\", color=TLS_COLOR)\n",
    "ax_bias_std.fill_between(bucket_centers_tls, means_tls - stds_tls, means_tls + stds_tls, color=TLS_COLOR, alpha=0.3)\n",
    "# manual\n",
    "# bucket_centers_manual, means_manual, stds_manual = smoothify(bucket_centers_manual, means_manual, stds_manual)\n",
    "ax_bias_std.plot(bucket_centers_manual, means_manual, label=\"Manual\", color=MANUAL_COLOR)\n",
    "ax_bias_std.fill_between(bucket_centers_manual, means_manual - stds_manual, means_manual + stds_manual, color=MANUAL_COLOR, alpha=0.3)\n",
    "ax_bias_std.set_xlabel(\"Coverage Angle [deg]\")\n",
    "ax_bias_std.set_ylabel(\"Error in DBH estimate [cm]\")\n",
    "fig_bias_std.savefig(\"/home/ori/Documents/Leonard/drs-docs-current/2024-iros-realtime-trees/pics/coverage_ablation_bias_std.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digiforest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
