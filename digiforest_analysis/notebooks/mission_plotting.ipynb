{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder\n",
    "mission_path = os.path.join(\n",
    "    Path().home(), \"digiforest_mission_data/2023-09-06-21-16-47\"\n",
    ")\n",
    "mission_path = \"/media/matias/T7/research/2024-autonomous-legged-forester-autonomy/2024-02-20-09-40-24-mission-forest-of-dean\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 1 / 2.54\n",
    "plot_width = 8.89 * cm\n",
    "plot_height = 8 * cm\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 8\n",
    "\n",
    "n_colors = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color palettes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = sns.color_palette(\"colorblind\", n_colors=n_colors, as_cmap=False)\n",
    "color_palette_str = [\n",
    "    \"blue\",\n",
    "    \"orange\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"pink\",\n",
    "    \"brown\",\n",
    "    \"light_pink\",\n",
    "    \"gray\",\n",
    "    \"yellow\",\n",
    "    \"light_blue\",\n",
    "]\n",
    "color_palette_str = {k: v for k, v in zip(color_palette_str, color_palette)}\n",
    "mpl_colorblind_cmap = ListedColormap(color_palette)\n",
    "\n",
    "# Okabe-Ito colormap: https://clauswilke.com/dataviz/color-pitfalls.html\n",
    "okabeito_palette_str = {\n",
    "    \"orange\": np.array([230, 159, 0]) / 255,\n",
    "    \"light_blue\": np.array([86, 180, 233]) / 255,\n",
    "    \"green\": np.array([0, 158, 115]) / 255,\n",
    "    \"yellow\": np.array([240, 228, 66]) / 255,\n",
    "    \"blue\": np.array([0, 114, 178]) / 255,\n",
    "    \"red\": np.array([213, 94, 0]) / 255,\n",
    "    \"pink\": np.array([204, 121, 167]) / 255,\n",
    "    \"black\": np.array([0, 0, 0]) / 255,\n",
    "}\n",
    "okabeito_palette = okabeito_palette_str.values()\n",
    "mpl_okabeito_cmap = ListedColormap(okabeito_palette)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscale palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_palette = [(c, c, c) for c in np.linspace(0, 1, n_colors + 1)]\n",
    "\n",
    "gray_palette_str = {f\"{n_colors - p}0\": v for p, v in enumerate(gray_palette)}\n",
    "gray_palette_str[\"black\"] = gray_palette_str[\"100\"]\n",
    "gray_palette_str[\"white\"] = gray_palette_str[\"00\"]\n",
    "\n",
    "mpl_gray_cmap = ListedColormap(gray_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_palette = sns.light_palette(\n",
    "    color_palette_str[\"blue\"], reverse=True, n_colors=n_colors + 1\n",
    ")\n",
    "blue_palette_str = {f\"{n_colors - p}0\": v for p, v in enumerate(blue_palette)}\n",
    "mpl_blue_cmap = ListedColormap(blue_palette)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divergent palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_palette = sns.blend_palette(\n",
    "    [color_palette[0], [1, 1, 1], color_palette[3]], n_colors=n_colors, as_cmap=False\n",
    ")\n",
    "mpl_div_cmap = ListedColormap(div_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = np.linspace(0, 1, n_colors)\n",
    "gradient = np.vstack((gradient, gradient))\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    5, 1, figsize=(2, 3), constrained_layout=False, dpi=200, sharex=True\n",
    ")\n",
    "ax[0].imshow(gradient, aspect=\"auto\", cmap=mpl_colorblind_cmap)\n",
    "ax[1].imshow(gradient, aspect=\"auto\", cmap=mpl_okabeito_cmap)\n",
    "ax[2].imshow(gradient, aspect=\"auto\", cmap=mpl_gray_cmap)\n",
    "ax[3].imshow(gradient, aspect=\"auto\", cmap=mpl_blue_cmap)\n",
    "ax[4].imshow(gradient, aspect=\"auto\", cmap=mpl_div_cmap)\n",
    "\n",
    "gradient = np.linspace(0, 1, n_colors)[None].repeat(n_colors, axis=0)\n",
    "for i in range(n_colors):\n",
    "    gradient[i] = np.roll(gradient[i], i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other params\n",
    "BASE_INVERTED = True\n",
    "SENSOR_RANGE_NOMINAL = 100  # radius, in meters, VLP-16\n",
    "SENSOR_RANGE_EFFECTIVE = 15  # radius, in meters, VLP-16\n",
    "\n",
    "FOOT_RADIUS = 0.03  # meters\n",
    "FOOT_AREA = np.pi * FOOT_RADIUS**2  # square meters\n",
    "\n",
    "REFERENCE_FRAMES = [\"base_vilens\", \"map\"]\n",
    "QUERY_FRAMES = [\"LF_FOOT\", \"LH_FOOT\", \"RF_FOOT\", \"RH_FOOT\"]\n",
    "\n",
    "FOOT_MAPPER = {}\n",
    "\n",
    "\n",
    "if BASE_INVERTED:\n",
    "    FOOT_MAPPER[\"LF_FOOT\"] = \"right hind\"\n",
    "    FOOT_MAPPER[\"LH_FOOT\"] = \"right front\"\n",
    "    FOOT_MAPPER[\"RF_FOOT\"] = \"left hind\"\n",
    "    FOOT_MAPPER[\"RH_FOOT\"] = \"left front\"\n",
    "else:\n",
    "    FOOT_MAPPER[\"LF_FOOT\"] = \"left front\"\n",
    "    FOOT_MAPPER[\"LH_FOOT\"] = \"left hind\"\n",
    "    FOOT_MAPPER[\"RF_FOOT\"] = \"right front\"\n",
    "    FOOT_MAPPER[\"RH_FOOT\"] = \"right hind\"\n",
    "\n",
    "FOOT_SYMBOL = {}\n",
    "FOOT_SYMBOL[\"LF_FOOT\"] = \"d\"  # diamond\n",
    "FOOT_SYMBOL[\"LH_FOOT\"] = \"o\"  # sphere\n",
    "FOOT_SYMBOL[\"RF_FOOT\"] = \"^\"  # triangle\n",
    "FOOT_SYMBOL[\"RH_FOOT\"] = \"P\"  # star\n",
    "\n",
    "FOOT_COLOR = {}\n",
    "FOOT_COLOR[\"LF_FOOT\"] = color_palette_str[\"blue\"]\n",
    "FOOT_COLOR[\"LH_FOOT\"] = color_palette_str[\"orange\"]\n",
    "FOOT_COLOR[\"RF_FOOT\"] = color_palette_str[\"green\"]\n",
    "FOOT_COLOR[\"RH_FOOT\"] = color_palette_str[\"red\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pose files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "def read_poses_file(filename, base_inverted=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Generate timestamp from sec and nsec\n",
    "    ts = 1e9 * df[\"sec\"] + df[\"nsec\"]  # In nanoseconds\n",
    "    df.index = pd.to_datetime(ts)\n",
    "    df = df[~df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    # Parse data\n",
    "    poses = {}\n",
    "    for ts, x, y, z, qx, qy, qz, qw in zip(\n",
    "        df.index, df[\"x\"], df[\"y\"], df[\"z\"], df[\"qx\"], df[\"qy\"], df[\"qz\"], df[\"qw\"]\n",
    "    ):\n",
    "        poses[f\"{ts:.10f}\"] = np.eye(4)\n",
    "        poses[f\"{ts:.10f}\"][0:3, 3] = np.array([x, y, z])\n",
    "        poses[f\"{ts:.10f}\"][0:3, 0:3] = R.from_quat([qx, qy, qz, qw]).as_matrix()\n",
    "\n",
    "        # TODO: fix base inversion\n",
    "\n",
    "    return df, poses\n",
    "\n",
    "\n",
    "df_state_poses, poses_list = read_poses_file(\n",
    "    os.path.join(mission_path, \"states/state_pose_data.csv\"),\n",
    "    base_inverted=BASE_INVERTED,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load twist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_twist_file(filename, base_inverted=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Generate timestamp from sec and nsec\n",
    "    ts = 1e9 * df[\"sec\"] + df[\"nsec\"]  # In nanoseconds\n",
    "    df.index = pd.to_datetime(ts)\n",
    "    df = df[~df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    # Correct twist due to base inversion\n",
    "    if BASE_INVERTED:\n",
    "        df[\"vx\"] *= -1\n",
    "        df[\"vy\"] *= -1\n",
    "\n",
    "    # Speeds\n",
    "    df[\"lin_speed\"] = (df[\"vx\"] ** 2 + df[\"vy\"] ** 2).pow(1.0 / 2)\n",
    "    df[\"ang_speed\"] = df[\"wz\"].abs()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_state_twist = read_twist_file(\n",
    "    os.path.join(mission_path, \"states/state_twist_data.csv\"),\n",
    "    base_inverted=BASE_INVERTED,\n",
    ")\n",
    "df_reference_twist = read_twist_file(\n",
    "    os.path.join(mission_path, \"states/reference_twist_data.csv\"),\n",
    "    base_inverted=BASE_INVERTED,\n",
    ")\n",
    "df_operator_twist = read_twist_file(\n",
    "    os.path.join(mission_path, \"states/operator_twist_data.csv\"),\n",
    "    base_inverted=BASE_INVERTED,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load other operator's signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_param_change_file(filename, base_inverted=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Generate timestamp from sec and nsec\n",
    "    ts = 1e9 * df[\"sec\"] + df[\"nsec\"]  # In nanoseconds\n",
    "    df.index = pd.to_datetime(ts)\n",
    "    df = df[~df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# df_local_planner_param = read_param_change_file(\n",
    "#     os.path.join(mission_path, \"states/local_planner_param_data.csv\"),\n",
    "# )\n",
    "# df_rmp_param = read_param_change_file(\n",
    "#     os.path.join(mission_path, \"states/rmp_param_data.csv\"),\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = {}\n",
    "for parent in REFERENCE_FRAMES:\n",
    "    for child in QUERY_FRAMES:\n",
    "        prefix = f\"{parent}_{child}\"\n",
    "        df, poses = read_poses_file(\n",
    "            os.path.join(mission_path, f\"states/{prefix}_data.csv\"),\n",
    "            base_inverted=BASE_INVERTED,\n",
    "        )\n",
    "\n",
    "        df_tf[prefix] = df.copy(deep=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all indices\n",
    "joined_indices = pd.Index(df_tf[prefix].index)\n",
    "for k, v in df_tf.items():\n",
    "    joined_indices = joined_indices.union(v.index)\n",
    "\n",
    "joined_indices = joined_indices.drop_duplicates()\n",
    "\n",
    "for k, v in df_tf.items():\n",
    "    df_tf[k] = df_tf[k].reindex(\n",
    "        index=joined_indices,\n",
    "    )\n",
    "    df_tf[k] = df_tf[k].interpolate(method=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "\n",
    "total_footsteps = 0\n",
    "footsteps = {}\n",
    "for foot in [\"LF_FOOT\", \"RF_FOOT\", \"LH_FOOT\", \"RH_FOOT\"]:\n",
    "    prefix = f\"base_vilens_{foot}\"\n",
    "    off = 0\n",
    "    dt = -1\n",
    "    y = df_tf[prefix][\"z\"][off : off + dt]\n",
    "    sy = df_tf[prefix][\"z\"].rolling(5, center=True).mean()[off : off + dt]\n",
    "    t = df_tf[prefix][\"z\"].index[off : off + dt]\n",
    "\n",
    "    peaks, properties = signal.find_peaks(-sy, distance=10, prominence=0.01)\n",
    "    footsteps[foot] = peaks\n",
    "\n",
    "    print(\n",
    "        \"phase period: \",\n",
    "        1\n",
    "        / df_tf[\"base_vilens_LF_FOOT\"][\"z\"][peaks]\n",
    "        .index.to_series()\n",
    "        .diff()\n",
    "        .mean()\n",
    "        .total_seconds(),\n",
    "    )\n",
    "    # ax.plot(t, y, linewidth=0.5)\n",
    "    # ax.plot(t, sy, linewidth=0.5)\n",
    "    # ax.plot(t[peaks], y[peaks], marker=\"x\", linewidth=0)\n",
    "    total_footsteps += peaks.size\n",
    "\n",
    "    print(f\"num_footsteps: {peaks.size}\")\n",
    "\n",
    "\n",
    "# nout = 100\n",
    "# w = np.linspace(0.001, 10, nout)\n",
    "# pgram = signal.lombscargle(df_tf[\"base_vilens_LF_FOOT\"][\"z\"].index[0:300], df_tf[\"base_vilens_LF_FOOT\"][\"z\"][0:300], w)\n",
    "# plt.plot(pgram)\n",
    "# plt.show()\n",
    "# pgram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SLAM graph\n",
    "Required for distance computation and coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slam, slam_graph = read_poses_file(\n",
    "    os.path.join(mission_path, \"states/slam_graph_data.csv\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend indices\n",
    "joined_indices = df_state_twist.index.union(df_reference_twist.index).drop_duplicates()\n",
    "joined_indices = joined_indices.union(df_operator_twist.index).drop_duplicates()\n",
    "\n",
    "joined_indices = joined_indices.union(df_local_planner_param.index).drop_duplicates()\n",
    "joined_indices = joined_indices.union(df_rmp_param.index).drop_duplicates()\n",
    "\n",
    "df_state_twist = df_state_twist.reindex(index=joined_indices)\n",
    "df_state_twist = df_state_twist.interpolate(method=\"index\")\n",
    "\n",
    "df_operator_twist = df_operator_twist.reindex(index=joined_indices)\n",
    "df_operator_twist = df_operator_twist.interpolate(method=\"index\")\n",
    "\n",
    "df_reference_twist = df_reference_twist.reindex(index=joined_indices)\n",
    "df_reference_twist = df_reference_twist.interpolate(method=\"index\")\n",
    "\n",
    "# df_local_planner_param = df_local_planner_param.reindex(index=joined_indices)\n",
    "# df_rmp_param = df_rmp_param.reindex(index=joined_indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator interventions\n",
    "This is required for autonomy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interventions from safety officer\n",
    "df_state_twist[\"safety_intervention\"] = df_operator_twist[\"lin_speed\"] > 0.0\n",
    "df_state_twist[\"safety_intervention\"] = df_state_twist[\n",
    "    \"safety_intervention\"\n",
    "].interpolate(method=\"pad\")\n",
    "\n",
    "# # Interventions from forestry operator\n",
    "# df_state_twist[\"operator_intervention\"] = (~df_local_planner_param[\"sec\"].isna()) + (\n",
    "#     ~df_rmp_param[\"sec\"].isna()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_state_twist[\"safety_intervention\"])\n",
    "# plt.plot(df_operator_twist[\"lin_speed\"] > 0.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate covered area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odom_points = df_state_poses[[\"x\", \"y\"]].to_numpy()\n",
    "slam_points = df_slam[[\"x\", \"y\"]].to_numpy()\n",
    "\n",
    "import shapely\n",
    "import shapely.plotting\n",
    "\n",
    "sp_odom_points = shapely.MultiPoint(odom_points)\n",
    "sp_slam_points = shapely.MultiPoint(slam_points)\n",
    "# sp_slam_hull = sp_slam_points.convex_hull\n",
    "\n",
    "sp_sensing_area_nominal = sp_slam_points.buffer(SENSOR_RANGE_NOMINAL)\n",
    "sp_sensing_area_effective = sp_slam_points.buffer(SENSOR_RANGE_EFFECTIVE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ts = df_state_twist.index[0]\n",
    "\n",
    "df_state_poses.index = df_state_poses.index - ref_ts\n",
    "df_state_twist.index = df_state_twist.index - ref_ts\n",
    "df_reference_twist.index = df_reference_twist.index - ref_ts\n",
    "df_operator_twist.index = df_operator_twist.index - ref_ts\n",
    "df_slam.index = df_slam.index - ref_ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "\n",
    "stats = {}\n",
    "\n",
    "# Constants\n",
    "stats[\"sqm_to_ha\"] = 0.0001\n",
    "stats[\"sec_to_min\"] = 1 / 60\n",
    "stats[\"sec_to_hour\"] = 1 / 3600\n",
    "\n",
    "# Speed\n",
    "stats[\"max_lin_speed\"] = df_state_twist[\"lin_speed\"].max().item()\n",
    "stats[\"min_lin_speed\"] = df_state_twist[\"lin_speed\"].min().item()\n",
    "stats[\"mean_lin_speed\"] = df_state_twist[\"lin_speed\"].mean().item()\n",
    "stats[\"std_lin_speed\"] = df_state_twist[\"lin_speed\"].std().item()\n",
    "\n",
    "stats[\"mean_ang_speed\"] = df_state_twist[\"ang_speed\"].mean().item()\n",
    "stats[\"std_ang_speed\"] = df_state_twist[\"ang_speed\"].std().item()\n",
    "\n",
    "# Distance walked\n",
    "stats[\"distance_m\"] = (\n",
    "    df_slam[[\"x\", \"y\", \"z\"]]\n",
    "    .diff()\n",
    "    .apply(lambda values: sum([v**2 for v in values]), axis=1)\n",
    "    .sum()\n",
    ").item()\n",
    "\n",
    "# Footsteps\n",
    "stats[\"footsteps\"] = total_footsteps\n",
    "stats[\"footsteps_area_m2\"] = total_footsteps * FOOT_AREA\n",
    "\n",
    "# Mission time\n",
    "stats[\"time_sec\"] = (df_slam.index[-1] - df_slam.index[0]).total_seconds()\n",
    "\n",
    "# Interventions\n",
    "stats[\"safety_intervention_sec\"] = integrate.simpson(\n",
    "    df_state_twist[\"safety_intervention\"], df_state_twist.index.total_seconds()\n",
    ").item()\n",
    "\n",
    "# stats[\"operator_intervention_sec\"] = integrate.simpson(\n",
    "#     df_state_twist[\"operator_intervention\"], df_state_twist.index.total_seconds()\n",
    "# ).item()\n",
    "\n",
    "# Percentaje of interventions\n",
    "stats[\"safety_intervention_perc\"] = (\n",
    "    stats[\"safety_intervention_sec\"] / stats[\"time_sec\"] * 100\n",
    ")\n",
    "# stats[\"operator_intervention_perc\"] = (\n",
    "#     stats[\"operator_intervention_sec\"] / stats[\"time_sec\"] * 100\n",
    "# )\n",
    "\n",
    "# Area covered\n",
    "stats[\"sensor_range_nominal_m\"] = SENSOR_RANGE_NOMINAL\n",
    "stats[\"sensed_area_nominal_m2\"] = sp_sensing_area_nominal.area\n",
    "stats[\"sensed_area_nominal_ha\"] = sp_sensing_area_nominal.area * stats[\"sqm_to_ha\"]\n",
    "\n",
    "stats[\"sensor_range_effective_m\"] = SENSOR_RANGE_EFFECTIVE\n",
    "stats[\"sensed_area_effective_m2\"] = sp_sensing_area_effective.area\n",
    "stats[\"sensed_area_effective_ha\"] = sp_sensing_area_effective.area * stats[\"sqm_to_ha\"]\n",
    "\n",
    "# Hectares per second\n",
    "stats[\"ha_per_sec\"] = stats[\"sensed_area_effective_ha\"] / stats[\"time_sec\"]\n",
    "stats[\"ha_per_min\"] = stats[\"sensed_area_effective_ha\"] / (\n",
    "    stats[\"time_sec\"] * stats[\"sec_to_min\"]\n",
    ")\n",
    "stats[\"ha_per_hour\"] = stats[\"sensed_area_effective_ha\"] / (\n",
    "    stats[\"time_sec\"] * stats[\"sec_to_hour\"]\n",
    ")\n",
    "\n",
    "# Print\n",
    "for k, v in stats.items():\n",
    "    print(f\"{k:>8}: {v:<20.2f}\")\n",
    "\n",
    "# Save as YAML\n",
    "import yaml\n",
    "\n",
    "file = open(os.path.join(mission_path, \"mission_report.yaml\"), \"w\")\n",
    "yaml.dump(stats, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate.simpson(\n",
    "    df_state_twist[\"safety_intervention\"], df_state_twist.index.total_seconds()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covered area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digiforest_analysis.utils.plotting import lighten\n",
    "\n",
    "# Plotting\n",
    "plot_width = 15 * cm\n",
    "plot_height = 15 * cm\n",
    "alpha = 0.7\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    1, 1, figsize=(plot_width, plot_height), constrained_layout=False, dpi=300\n",
    ")\n",
    "# Axes\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(which=\"major\", color=gray_palette_str[\"20\"], linewidth=0.7)\n",
    "ax.grid(which=\"minor\", color=gray_palette_str[\"10\"], linestyle=\":\", linewidth=0.5)\n",
    "ax.minorticks_on()\n",
    "\n",
    "\n",
    "# shapely.plotting.plot_points(\n",
    "#     sp_odom_points,\n",
    "#     markersize=1,\n",
    "#     marker=\".\",\n",
    "#     color=gray_palette[1],\n",
    "#     alpha=0.5,\n",
    "#     fillstyle=\"full\",\n",
    "#     linewidth=0,\n",
    "#     label=\"Odometry\",\n",
    "# ax=ax,\n",
    "# )\n",
    "\n",
    "# Plot sensor polygon\n",
    "shapely.plotting.plot_polygon(\n",
    "    sp_sensing_area_nominal,\n",
    "    add_points=False,\n",
    "    linewidth=0,\n",
    "    alpha=alpha,\n",
    "    color=blue_palette_str[\"30\"],\n",
    "    label=f\"Nominal sensing range ({SENSOR_RANGE_NOMINAL} m)\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "shapely.plotting.plot_polygon(\n",
    "    sp_sensing_area_effective,\n",
    "    add_points=False,\n",
    "    linewidth=0,\n",
    "    alpha=alpha,\n",
    "    color=blue_palette_str[\"50\"],\n",
    "    label=f\"Effective sensing range ({SENSOR_RANGE_EFFECTIVE} m)\",\n",
    ")\n",
    "\n",
    "\n",
    "# shapely.plotting.plot_polygon(hull, add_points=False)\n",
    "\n",
    "# Add footsteps\n",
    "# for i, (foot, v) in enumerate(footsteps.items()):\n",
    "#     prefix = f\"map_vilens_{foot}\"\n",
    "#     ax.scatter(\n",
    "#         df_tf[prefix][\"x\"][v],\n",
    "#         df_tf[prefix][\"y\"][v],\n",
    "#         s=2,\n",
    "#         marker=FOOT_SYMBOLS[foot],\n",
    "#         edgecolor=\"none\",\n",
    "#         alpha=1,\n",
    "#         label=FOOT_MAPPER[foot],\n",
    "#         color=color_palette[i],\n",
    "#     )\n",
    "\n",
    "list_arrays = [\n",
    "    np.array((geom.xy[0][0], geom.xy[1][0])) for geom in sp_slam_points.geoms\n",
    "]\n",
    "sp_slam_line = shapely.LineString(list_arrays)\n",
    "shapely.plotting.plot_line(\n",
    "    sp_slam_line,\n",
    "    linewidth=1,\n",
    "    color=gray_palette_str[\"80\"],\n",
    "    alpha=1.0,\n",
    "    add_points=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Plot points\n",
    "shapely.plotting.plot_points(\n",
    "    sp_slam_points,\n",
    "    markersize=2,\n",
    "    marker=\"o\",\n",
    "    color=gray_palette_str[\"80\"],\n",
    "    alpha=1.0,\n",
    "    fillstyle=\"full\",\n",
    "    label=\"SLAM path\",\n",
    ")\n",
    "\n",
    "\n",
    "lgnd = ax.legend(edgecolor=(1, 1, 1, 0), framealpha=0.9, loc=(0, 1.01), ncol=2)\n",
    "for handle in lgnd.legend_handles:\n",
    "    try:\n",
    "        handle.set_sizes([40.0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "for handle in lgnd.get_lines():\n",
    "    handle.set_linewidth(1)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"x [m]\")\n",
    "ax.set_ylabel(\"y [m]\")\n",
    "ax.margins(x=0.1, y=0.1)\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(os.path.join(mission_path, \"sensed_area.pdf\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robot velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_window = \"3000ms\"\n",
    "linewidth = 1\n",
    "\n",
    "plot_width = 15 * cm\n",
    "plot_height = 6 * cm\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    1,\n",
    "    1,\n",
    "    figsize=(plot_width, plot_height),\n",
    "    constrained_layout=False,\n",
    "    dpi=300,\n",
    "    sharex=True,\n",
    ")\n",
    "# Axes\n",
    "ax.set_axisbelow(True)\n",
    "# ax.set_aspect(\"equal\")\n",
    "ax.grid(which=\"major\", color=gray_palette_str[\"20\"], linewidth=0.7)\n",
    "ax.grid(which=\"minor\", color=gray_palette_str[\"10\"], linestyle=\":\", linewidth=0.5)\n",
    "ax.minorticks_on()\n",
    "\n",
    "ax.plot(\n",
    "    df_state_twist.index.total_seconds(),\n",
    "    df_state_twist[\"lin_speed\"].rolling(smoothing_window, center=True).mean(),\n",
    "    label=\"Robot speed\",\n",
    "    linewidth=linewidth,\n",
    "    color=color_palette_str[\"blue\"],\n",
    ")\n",
    "ax.plot(\n",
    "    df_reference_twist.index.total_seconds(),\n",
    "    df_reference_twist[\"lin_speed\"].rolling(smoothing_window, center=True).mean(),\n",
    "    label=\"Local planner reference\",\n",
    "    linewidth=linewidth,\n",
    "    color=color_palette_str[\"orange\"],\n",
    ")\n",
    "\n",
    "# ax[1].plot(\n",
    "#     df_operator_twist.index.total_seconds(),\n",
    "#     df_operator_twist[\"lin_speed\"].rolling(smoothing_window, center=True).mean(),\n",
    "#     label=\"Operator command\",\n",
    "#     linewidth=linewidth,\n",
    "#     color=color_palette[2],\n",
    "# )\n",
    "\n",
    "# if df_state_twist[\"operator_intervention\"].any():\n",
    "#     ax.fill_between(\n",
    "#         df_state_twist[\"operator_intervention\"].index.total_seconds(),\n",
    "#         df_state_twist[\"operator_intervention\"].index.total_seconds() * 0,\n",
    "#         df_state_twist[\"operator_intervention\"],\n",
    "#         label=\"Operator action\",\n",
    "#         linewidth=1,\n",
    "#         linestyle=\"-\",\n",
    "#         color=gray_palette_str[\"70\"],\n",
    "#         alpha=1.0,\n",
    "#     )\n",
    "\n",
    "if df_state_twist[\"safety_intervention\"].any():\n",
    "    ax.fill_between(\n",
    "        df_state_twist[\"safety_intervention\"].index.total_seconds(),\n",
    "        df_state_twist[\"safety_intervention\"].index.total_seconds() * 0,\n",
    "        df_state_twist[\"safety_intervention\"],\n",
    "        label=\"Safety intervention\",\n",
    "        linewidth=0,\n",
    "        color=gray_palette_str[\"40\"],\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "\n",
    "# ax[1].plot(\n",
    "#     df_reference_twist.index.total_seconds(),\n",
    "#     (df_reference_twist[\"lin_speed\"].rolling(smoothing_window, center=True).mean() - df_state_twist[\"lin_speed\"].rolling(smoothing_window, center=True).mean()),\n",
    "#     label=\"Operator command\",\n",
    "#     linewidth=linewidth,\n",
    "#     color=color_palette[3],\n",
    "# )\n",
    "\n",
    "# Legends\n",
    "lgnd = ax.legend(edgecolor=(1, 1, 1, 0), framealpha=0.9, loc=(0, 1.03), ncol=2)\n",
    "for handle in lgnd.legend_handles:\n",
    "    try:\n",
    "        handle.set_sizes([40.0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "for handle in lgnd.get_lines():\n",
    "    handle.set_linewidth(1)\n",
    "\n",
    "\n",
    "# ax.set_title('Computation Time')\n",
    "\n",
    "ax.margins(x=0, y=0)\n",
    "ax.set_ylabel(\"Speed [m/s]\")\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "\n",
    "# ax[1].margins(x=0, y=0)\n",
    "# ax[1].set_ylabel(\"Speed [m/s]\")\n",
    "# ax.set_xlabel(\"Time [s]\")\n",
    "\n",
    "# Export\n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(os.path.join(mission_path, \"mission_velocity.pdf\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autonomy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot footsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_width = 20 * cm\n",
    "plot_height = 15 * cm\n",
    "alpha = 0.8\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    1,\n",
    "    1,\n",
    "    figsize=(plot_width, plot_height),\n",
    "    constrained_layout=False,\n",
    "    dpi=300,\n",
    ")\n",
    "\n",
    "# Axes\n",
    "# [ax.spines[side].set_visible(False) for side in ax.spines] # Remove borders of plot\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(which=\"major\", color=gray_palette_str[\"20\"], linewidth=0.7)\n",
    "ax.grid(which=\"minor\", color=gray_palette_str[\"10\"], linestyle=\":\", linewidth=0.5)\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Add footsteps\n",
    "for i, (foot, v) in enumerate(footsteps.items()):\n",
    "    prefix = f\"map_{foot}\"\n",
    "    ax.scatter(\n",
    "        df_tf[prefix][\"x\"][v],\n",
    "        df_tf[prefix][\"y\"][v],\n",
    "        s=5,\n",
    "        marker=FOOT_SYMBOL[foot],\n",
    "        edgecolor=\"none\",\n",
    "        alpha=alpha,\n",
    "        label=FOOT_MAPPER[foot],\n",
    "        color=FOOT_COLOR[foot],\n",
    "    )\n",
    "\n",
    "lgnd = ax.legend(edgecolor=(1, 1, 1, 0), framealpha=0.9, loc=(0.01, 1.01), ncol=4)\n",
    "for handle in lgnd.legend_handles:\n",
    "    handle.set_sizes([40.0])\n",
    "\n",
    "# ax.set_title(\"Footsteps\")\n",
    "ax.set_xlabel(\"x [m]\")\n",
    "ax.set_ylabel(\"y [m]\")\n",
    "ax.margins(x=0.15, y=0.1)\n",
    "\n",
    "loc = plt.MultipleLocator(10.0)  # this locator puts ticks at regular intervals\n",
    "# ax.xaxis.set_major_locator(loc)\n",
    "ax.yaxis.set_major_locator(loc)\n",
    "\n",
    "# loc = plt.MultipleLocator(1.0) # this locator puts ticks at regular intervals\n",
    "# ax.xaxis.set_minor_locator(loc)\n",
    "# ax.yaxis.set_minor_locator(loc)\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(os.path.join(mission_path, \"footsteps.pdf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
